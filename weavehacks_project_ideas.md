# WeaveHacks Project Ideas & Strategy Guide

> **Event:** WeaveHacks - Self-Improving Agents Hackathon
> **Date:** January 31 - February 1, 2025
> **Location:** Weights & Biases SF Office
> **Prize Pool:** $15k+ including Unitree G2 Pro Robot Dog

---

## Table of Contents

1. [Previous Winning Projects Analysis](#previous-winning-projects-analysis)
2. [Winning Patterns](#winning-patterns)
3. [Judge Profiles & Preferences](#judge-profiles--preferences)
4. [Sponsor Tools Overview](#sponsor-tools-overview)
5. [Top 10 Project Ideas](#top-10-project-ideas)
6. [Judge-Optimized Strategy Matrix](#judge-optimized-strategy-matrix)
7. [Demo Strategy](#demo-strategy)
8. [Final Recommendations](#final-recommendations)

---

## Previous Winning Projects Analysis

### WeaveHacks 2 Winners (Self-Improving Agents Theme)

| Project | What It Did | Why It Won |
|---------|-------------|------------|
| **Daydreamer** | "GPT moment for robotics" - pretrain on video, imagine solutions, act, learn | Ambitious vision + clear improvement loop |
| **ReviveAgent** | Self-improving AI that resolves conflicts, refactors code, eliminates tech debt | Solves real developer pain |
| **The Convergence** | Agents that improve through experience, collaboration, evolution | Multi-agent + emergent behavior |
| **Silicon Valhalla** | Self-learning agent that injects up-to-date documentation into code agents | Addresses knowledge cutoffs |
| **Popstar** | Automating RL reward design for video games using LLMs | RL + LLMs combination |
| **SynErgi** | Self-evolving grid optimizer with GRPO RL | Real-world critical systems |
| **ContentEngine** | Self-improving content generation with agentic memory and RL | Memory + RL integration |
| **AVAX** | AI social media team that hires/fires its own agents | Accountability + self-management |
| **CO-DREAMER** | Knowledge graph generation with iterative RL for factual reasoning | Memory + RL for reasoning |
| **ERA** | Self-improving AI that builds other AIs | Meta-level: AI creating AI |
| **Product Mate** | User meetings to measurable impact automation | Practical workflow automation |

### WeaveHacks 1 Notable Projects

- **Deep Slack**: GPT Deep Research in Slack with scheduled reports
- **MCP-Powered Funnels**: OAuth-enabled MCP servers for DevTools
- **Voice-Control-Browser**: Hands-free web browsing
- **Research Lab Assistant**: Hands-free logging, real-time monitoring
- **Gyrus**: Agentic browser for critical thinking
- **RoboWeave**: Prompt-based multimodal control of embodied agents

---

## Winning Patterns

### The Winning Formula

```
WINNING PROJECT =
    (RL/Feedback Loop)
  + (Multi-Agent OR Memory System)
  + (Visible self-improvement in demo)
  + (Ambitious "paradigm shift" framing)
```

### Technical Patterns That Won

| Pattern | Frequency | Examples |
|---------|-----------|----------|
| **Reinforcement Learning** | 45% of winners | Daydreamer, Popstar, SynErgi, ContentEngine, CO-DREAMER |
| **Multi-Agent Systems** | 36% of winners | The Convergence, SynErgi, AVAX, ERA |
| **Memory Systems** | 27% of winners | ContentEngine, Silicon Valhalla, CO-DREAMER |

### Problem Domains That Won

```
Robotics/Embodied AI:    ███████████████  27% (3 projects)
Developer Tools:         ███████████████  27% (3 projects)
Content/Social:          ██████████       18% (2 projects)
Infrastructure/Energy:   █████            9%  (1 project)
Gaming:                  █████            9%  (1 project)
Product/Business:        █████            9%  (1 project)
```

### What Made Projects Stand Out

1. **Memorable Taglines**
   - "GPT moment for robotics" (Daydreamer)
   - "AI that hires/fires its own agents" (AVAX)
   - "Agents that build other AIs" (ERA)

2. **Closed-Loop Demonstrations**
   - Not just "AI does X" but "AI does X, evaluates, improves, does X better"
   - Visible iteration during demo time

3. **Ambitious but Grounded**
   - Big vision + working prototype

### Self-Improvement Mechanisms That Won

| Type | Projects | Description |
|------|----------|-------------|
| **Experience-Based** | Daydreamer, The Convergence, ContentEngine | Learn from interactions |
| **Generation-Based** | ERA, AVAX | Create new agents/code |
| **Optimization-Based** | Popstar, SynErgi, ReviveAgent | Refine existing solutions |

---

## Judge Profiles & Preferences

### Judges Who Favor Technical Depth

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Aleksa Gordic** | Ex-DeepMind, AI Epiphany YouTube | Research-grade implementations, novel architectures |
| **Lucas Atkins** | CTO at Arcee AI | Fine-tuning, model optimization, enterprise applications |
| **Shadi Saba** | CoreWeave, ex-AWS Neuron | Distributed systems, infrastructure, scale |

### Judges Who Favor Polish + Practicality

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Ray Fernando** | 12-year ex-Apple engineer | Apple-level UX, polished apps |
| **Vjeux** | Meta, React Native, Excalidraw creator | Beautiful UI, clean code, developer tools |
| **Jake Phelps** | Head of DevRel at Vercel | Frontend, deployment, developer experience |
| **Matthew Berman** | AI YouTuber, CodeRabbit | Demo-able projects, clear before/after |
| **Kwindla Kramer** | CEO of Daily, creator of Pipecat | Real-time voice/audio done well |

### Judges Who Favor Safety + Reliability

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Dex Horthy** | Founder of HumanLayer, "12 Factor Agents" | Human-in-the-loop, production safety |
| **Allie Howe** | "Insecure Agents" podcast | Agent security, adversarial robustness |
| **Karan Vaidya** | Co-founder of Composio | Secure tool integrations, SaaS automation |

### Other Notable Judges

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Sicheng Pan** | Technical Staff at Chroma | RAG, embeddings, memory systems |
| **Ivan Porollo** | Founder of Cerebral Valley | Community potential, go-to-market vision |

---

## Sponsor Tools Overview

### Available Tools & Their Strengths

| Sponsor | Tool | Key Capability | Best Use Case |
|---------|------|----------------|---------------|
| **Weights & Biases** | Weave | LLM tracing & observability | Track agent decisions, visualize improvement |
| **Redis** | Redis Cloud | Vector search, caching, fast memory | Memory systems, session state, similarity search |
| **Browserbase** | Browserbase + Stagehand | Web automation | Browser automation, web scraping, testing |
| **Vercel** | Vercel Platform | Frontend deployment | Instant deployment, edge functions, AI SDK |
| **Daily** | Daily + Pipecat | Real-time video/audio | Voice agents, real-time conversation |
| **Marimo** | Marimo Notebooks | Reproducible AI workflows | Interactive notebooks, sharing |
| **Google Cloud** | ADK + A2A | Agent development & communication | Agent-to-agent protocols, model serving |

---

## Top 10 Project Ideas

### 1. "VoiceCoach" - Real-Time Speech Improvement Agent

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Daily + Pipecat (voice AI), Weave (track improvement) |
| **Self-Improvement** | Learns which coaching tips actually help each user improve |
| **Demo Power** | Judge speaks → gets real-time feedback → sounds better in 60 seconds |
| **Target Judges** | Kwindla (Daily), Ray (UX), Matthew (demo-able) |

**Concept:**
A voice AI that helps users improve their public speaking by analyzing speech patterns in real-time and adapting its coaching style based on what feedback actually helps each user improve.

**Self-Improvement Mechanism:**
```python
class AdaptiveCoachPipeline(Pipeline):
    async def process_audio(self, frame: AudioFrame):
        metrics = analyze_speech(frame)  # Pace, fillers, clarity

        if needs_intervention(metrics):
            tip = select_tip(
                user_profile=self.user_learning_history,
                current_metrics=metrics
            )
            await self.speak(tip)

            # Self-improvement: track if tip worked
            asyncio.create_task(
                self.measure_improvement(tip.id, delay=30)
            )
```

**Why It Wins:**
- Real-time voice is technically hard - doing it smoothly proves competence
- Personalization through self-improvement is the killer feature
- Daily's infrastructure handles the hard parts (WebRTC, scaling)
- Perfect for live demo - judge actually gets better at speaking

**24-Hour Build Plan:**
1. Set up Pipecat pipeline with Daily
2. Implement 3 speech metrics (filler words, pace, volume)
3. Build tip selection with effectiveness tracking
4. Create simple UI showing improvement over time
5. Polish the voice responses

---

### 2. "WebSensei" - Self-Correcting Web Automation

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Browserbase + Stagehand |
| **Self-Improvement** | Automatically fixes broken scrapers, learns fallback patterns |
| **Demo Power** | "This scraper broke. WebSensei fixed it automatically." |
| **Target Judges** | Vjeux (DX), Matthew (demo), Jake (frontend) |

**Concept:**
A web scraping agent that detects when websites change structure, automatically fixes its own selectors, and builds resilience over time by learning patterns.

**Self-Improvement Mechanism:**
```typescript
const stagehand = new Stagehand({ browserbaseSessionID });

async function resilientScrape(url: string, target: string) {
  try {
    return await stagehand.extract({ instruction: target });
  } catch (e) {
    // Self-improvement: analyze failure, generate alternatives
    const newStrategy = await stagehand.act({
      action: `The previous selector failed. Analyze the page and find alternative ways to extract: ${target}`
    });

    // Save learning for future use
    await saveSelectorEvolution(url, target, newStrategy);
    return retry(newStrategy);
  }
}
```

**Why It Wins:**
- Solves REAL developer pain (everyone hates broken scrapers)
- Clear before/after demonstration
- Stagehand writes code, Browserbase runs it - perfect sponsor showcase
- The "self-healing" narrative is compelling

**24-Hour Build Plan:**
1. Set up Browserbase + Stagehand integration
2. Pick 3-5 popular sites that change frequently (news, e-commerce)
3. Build selector evolution history storage
4. Implement failure detection and recovery
5. Create dashboard showing recovery events

---

### 3. "AgentColony" - Multi-Agent Ecosystem with Emergent Specialization

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Google Cloud ADK + A2A protocol, Weave for tracking |
| **Self-Improvement** | Agents specialize over time based on task success |
| **Demo Power** | Watch agents naturally develop "expertise areas" |
| **Target Judges** | Aleksa (research), Shadi (infrastructure), Lucas (optimization) |

**Concept:**
A colony of agents that communicate via Google's A2A protocol, where agents specialize over time based on which tasks they succeed at—emergent division of labor through self-improvement.

**Self-Improvement Mechanism:**
```python
from google.adk import Agent, A2AProtocol

class EvolvingAgent(Agent):
    def __init__(self):
        self.competency_scores = defaultdict(lambda: 0.5)

    async def handle_task(self, task: A2AMessage):
        result = await self.attempt(task)

        # Self-improvement: update competency
        if result.success:
            self.competency_scores[task.type] *= 1.1
        else:
            self.competency_scores[task.type] *= 0.9

        # Broadcast updated capabilities to colony
        await self.broadcast_capabilities(self.competency_scores)
```

**Why It Wins:**
- A2A protocol used for its intended purpose: agent coordination
- Emergent behavior is fascinating and demo-able
- Shows deep understanding of Google's agent ecosystem vision
- Research-grade concept with practical implementation

**24-Hour Build Plan:**
1. Set up Google Cloud ADK with A2A
2. Create 3-5 generalist agents
3. Define 3-4 task types with clear success metrics
4. Build task router that learns from competency broadcasts
5. Create visualization dashboard showing specialization emerge

---

### 4. "TrustLoop" - Agent with Earned Autonomy

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Redis (fast permission lookups), Weave (audit trails) |
| **Self-Improvement** | Earns autonomy as it proves reliability |
| **Demo Power** | "Watch the agent graduate from supervised to autonomous" |
| **Target Judges** | Dex (safety), Allie (security), Karan (tool integration) |

**Concept:**
An AI agent that starts with heavy human oversight and earns autonomy as it proves reliability. Self-improves by learning from human corrections.

**Trust Model:**
```
New agent: 100% human oversight
After 100 successful actions in domain X: 50% oversight
After 1000 successful actions: 10% oversight with sampling
One failure: reset trust in that domain
```

**Self-Improvement Mechanism:**
```python
class TrustLoopAgent:
    def __init__(self):
        self.trust_scores = {}  # domain -> trust level
        self.redis = Redis()

    async def request_action(self, action, domain):
        trust = self.trust_scores.get(domain, 0.0)

        if trust < 0.5:
            # Requires human approval
            approved = await self.request_human_approval(action)
            if approved:
                result = await self.execute(action)
                self.update_trust(domain, result.success)
        elif trust < 0.9:
            # Sampling - 50% require approval
            if random.random() < (1 - trust):
                await self.request_human_approval(action)
            result = await self.execute(action)
            self.update_trust(domain, result.success)
        else:
            # Autonomous with logging
            result = await self.execute(action)
            weave.log({"action": action, "result": result, "autonomous": True})
```

**Why It Wins:**
- Directly addresses Dex Horthy's thesis (HumanLayer founder)
- Novel trust model that no one else will build
- Shows production mindset over "cool demo" mindset
- Redis for fast lookups proves infrastructure thinking

**24-Hour Build Plan:**
1. Set up Redis for permission/trust storage
2. Implement graduated trust model
3. Build human approval interface
4. Create Weave integration for audit trails
5. Demo workflow showing trust being earned

---

### 5. "ERA-Lite" - Meta-Agent That Builds Better Agents

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Weave (track agent variants), Vercel (deploy best agents) |
| **Self-Improvement** | Generates, tests, and refines specialized agents |
| **Demo Power** | "Our agent's first task was to improve itself" |
| **Target Judges** | Aleksa (research), Matthew (demo), Lucas (optimization) |

**Concept:**
An agent factory that generates, tests, and refines specialized agents. Uses Weave to track which agent architectures perform best.

**Self-Improvement Mechanism:**
```python
class MetaAgent:
    async def evolve_agent(self, task_type: str):
        # Generate agent variants
        variants = []
        for i in range(10):
            config = self.mutate_config(self.best_config[task_type])
            agent = self.create_agent(config)
            variants.append(agent)

        # Test all variants
        results = await asyncio.gather(*[
            self.evaluate_agent(agent, task_type)
            for agent in variants
        ])

        # Track in Weave
        for agent, result in zip(variants, results):
            weave.log({
                "agent_config": agent.config,
                "task_type": task_type,
                "score": result.score
            })

        # Keep best
        best = max(zip(variants, results), key=lambda x: x[1].score)
        self.best_config[task_type] = best[0].config
        return best[0]
```

**Why It Wins:**
- Direct callback to ERA (previous winner)
- "AI that builds AI" is the paradigm shift narrative
- Weave dashboard shows evolution over time
- Technically impressive but achievable

**24-Hour Build Plan:**
1. Define agent configuration space (prompts, tools, parameters)
2. Build mutation/crossover functions
3. Create evaluation harness with test tasks
4. Integrate Weave for tracking
5. Build dashboard showing agent evolution

---

### 6. "MemoryForge" - Agent with Self-Healing Knowledge Graph

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Redis (vector search for memory), Weave (track contradictions) |
| **Self-Improvement** | Finds and resolves contradictions in its own memory |
| **Demo Power** | "Watch the agent discover it was wrong and fix itself" |
| **Target Judges** | Sicheng (Chroma/RAG), Aleksa (research), Lucas (optimization) |

**Concept:**
A personal research assistant that builds and REFINES its knowledge graph over time, using Redis vector search to find contradictions in its own memory and resolve them.

**Self-Improvement Mechanism:**
```python
class MemoryForge:
    async def add_memory(self, content: str):
        embedding = await self.embed(content)

        # Search for conflicting memories
        conflicts = await self.redis.ft("idx:memories").search(
            Query(f"@embedding:[VECTOR_RANGE 0.15 $vec]")
            .return_fields("content", "confidence")
        )

        # Resolve conflicts
        for conflict in conflicts:
            if self.is_contradiction(content, conflict.content):
                resolution = await self.resolve_contradiction(
                    new=content,
                    old=conflict.content
                )
                await self.update_memory(conflict.id, resolution)
                weave.log({
                    "event": "contradiction_resolved",
                    "old": conflict.content,
                    "new": content,
                    "resolution": resolution
                })

        # Store new memory
        await self.redis.hset(f"memory:{id}", mapping={
            "embedding": embedding.tobytes(),
            "content": content,
            "confidence": 0.7,
            "last_validated": timestamp
        })
```

**Why It Wins:**
- Redis isn't just a cache—it's the SUBSTRATE for self-improvement
- Vector search enables "memory introspection"
- Shows sophisticated use of sponsor tech
- Sicheng (Chroma) will appreciate the approach

**24-Hour Build Plan:**
1. Set up Redis with vector search index
2. Pre-load with a specific domain (e.g., AI research papers)
3. Build contradiction detection logic
4. Implement resolution strategies
5. Create visualization of memory health improving

---

### 7. "DeployBot" - Self-Optimizing Vercel Application

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Vercel (deployment + analytics), Weave (track experiments) |
| **Self-Improvement** | A/B tests its own prompts, auto-deploys winners |
| **Demo Power** | "Conversion improved 23% after 3 auto-deployments" |
| **Target Judges** | Jake (Vercel), Matthew (demo), Vjeux (DX) |

**Concept:**
A Vercel-deployed AI app that monitors its own performance metrics and automatically deploys improvements to itself—prompt refinements, caching strategies, and edge function optimizations.

**Self-Improvement Mechanism:**
```typescript
// Edge function with self-improvement hooks
export const config = { runtime: 'edge' };

export default async function handler(req: Request) {
  const variant = await getActivePromptVariant(); // A/B test
  const start = Date.now();

  const response = await generateAIResponse(variant);

  // Log for self-improvement analysis
  await logToAnalytics({
    variant: variant.id,
    latency: Date.now() - start,
    tokenCount: response.usage.total_tokens,
    userSatisfaction: await getUserFeedback()
  });

  // Check if we have statistical significance
  const analysis = await analyzeVariants();
  if (analysis.hasWinner) {
    await deployWinningVariant(analysis.winner);
  }

  return new Response(response.content);
}
```

**Why It Wins:**
- Meta-demonstration: the product improves itself
- Jake Phelps (Vercel) will love seeing Vercel capabilities showcased
- Real metrics proving improvement
- Shows understanding of deployment/analytics integration

**24-Hour Build Plan:**
1. Set up Vercel AI SDK project
2. Implement A/B testing for prompts
3. Create analytics tracking with Weave
4. Build auto-deployment via Vercel API
5. Create dashboard showing improvement over time

---

### 8. "GuardianAgent" - Self-Improving Security Layer

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Weave (audit trails), Redis (fast policy lookups) |
| **Self-Improvement** | Learns new attack patterns, builds defenses automatically |
| **Demo Power** | Show unsafe agent causing chaos → GuardianAgent prevents disaster |
| **Target Judges** | Dex (safety), Allie (security), Karan (tool integration) |

**Concept:**
A security layer that monitors agent actions for safety violations, learns new attack patterns, and builds defenses. Human-in-the-loop for high-risk actions.

**Self-Improvement Mechanism:**
```python
class GuardianAgent:
    def __init__(self):
        self.policy_embeddings = []  # Known bad patterns
        self.redis = Redis()

    async def evaluate_action(self, action: AgentAction) -> Decision:
        # Check against known patterns
        embedding = await self.embed(action.description)
        similar_violations = await self.redis.ft("violations").search(
            Query(f"@embedding:[VECTOR_RANGE 0.2 $vec]")
        )

        if similar_violations:
            # Block and log
            weave.log({
                "event": "action_blocked",
                "action": action,
                "similar_to": similar_violations[0]
            })
            return Decision.BLOCK

        # Risk assessment
        risk = await self.assess_risk(action)
        if risk > 0.7:
            # Human approval required
            approved = await self.request_approval(action, risk)
            if not approved:
                # Learn from rejection
                await self.add_violation_pattern(action)
            return Decision.APPROVED if approved else Decision.BLOCK

        return Decision.ALLOW
```

**Why It Wins:**
- Combines Weave + Redis meaningfully
- Addresses real concerns (Dex, Allie care deeply)
- "Horror story → save" demo is memorable
- Shows production mindset

**24-Hour Build Plan:**
1. Set up Redis for policy/violation storage
2. Build risk assessment model
3. Create human approval interface
4. Implement learning from rejections
5. Prepare demo scenarios showing protection

---

### 9. "NotebookEvolver" - Self-Documenting Research Agent

**Win Probability: MEDIUM** ⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Marimo (reactive notebooks), Weave (track experiments) |
| **Self-Improvement** | Learns which research approaches work vs. fail |
| **Demo Power** | The notebook IS the agent's evolving brain |
| **Target Judges** | Aleksa (research), Sicheng (data), Lucas (ML) |

**Concept:**
An AI research assistant that lives IN a Marimo notebook, runs experiments, and automatically improves its own methodology based on which experiments yield insights vs. dead ends.

**Self-Improvement Mechanism:**
```python
import marimo as mo

@mo.cell
def experiment_runner():
    # Agent proposes experiments
    experiment = agent.propose_experiment(
        goal=research_question,
        past_failures=get_failed_approaches(),
        successful_patterns=get_working_methods()
    )

    # Run and evaluate
    result = run_experiment(experiment)

    # Self-improvement: classify outcome
    if result.insight_score > threshold:
        save_successful_pattern(experiment.methodology)
        mo.md(f"## Success! New pattern learned: {experiment.methodology}")
    else:
        save_failure_reason(experiment, result.why_failed)
        mo.md(f"## Failed: {result.why_failed}. Avoiding this approach.")

    return result
```

**Why It Wins:**
- Marimo's reactivity makes the improvement loop VISIBLE
- The notebook IS the agent's evolving brain
- Reproducibility means judges can verify claims
- Novel use case for notebooks

**24-Hour Build Plan:**
1. Set up Marimo notebook environment
2. Focus on specific research domain (e.g., hyperparameter optimization)
3. Build experiment proposal and evaluation
4. Create methodology memory system
5. Pre-seed with some failures to show evolution

---

### 10. "Daydreamer-Lite" - Video-to-Action Learning Agent

**Win Probability: MEDIUM (High ceiling, high risk)** ⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Browserbase (execute learned actions), Weave (track learning) |
| **Self-Improvement** | Watches tutorials, extracts actions, tries them, learns |
| **Demo Power** | Agent watches YouTube tutorial → executes workflow → improves |
| **Target Judges** | Aleksa (research), Shadi (ambitious), Matthew (wow factor) |

**Concept:**
Inspired by the Daydreamer winner. An agent that watches video tutorials, extracts actions, tries them in a browser, and learns from success/failure.

**Self-Improvement Mechanism:**
```python
class DaydreamerLite:
    async def learn_from_video(self, video_url: str):
        # Extract action sequence from video
        frames = await self.extract_frames(video_url)
        actions = await self.vision_model.extract_actions(frames)

        # Attempt in browser
        browser = await Browserbase.create_session()
        results = []

        for action in actions:
            try:
                result = await browser.execute(action)
                results.append({"action": action, "success": True})
            except Exception as e:
                results.append({"action": action, "success": False, "error": str(e)})

                # Learn from failure
                correction = await self.analyze_failure(action, e)
                self.action_corrections[action.type].append(correction)

        # Log learning
        weave.log({
            "video": video_url,
            "actions_extracted": len(actions),
            "success_rate": sum(r["success"] for r in results) / len(results),
            "corrections_learned": len(self.action_corrections)
        })
```

**Why It Wins:**
- Direct callback to the grand prize winner (Daydreamer)
- "GPT moment" narrative framing
- Technically ambitious = high judge respect if it works
- Combines vision + action + learning

**Risk:** Video processing is slow; demo must be bulletproof

**24-Hour Build Plan:**
1. Pre-process 5 tutorial videos for common workflows
2. Set up Browserbase for action execution
3. Build action extraction from video (can use GPT-4V)
4. Implement failure analysis and correction
5. Demo the 6th video being learned LIVE

---

## Judge-Optimized Strategy Matrix

| Project | Dex (Safety) | Kwindla (Voice) | Vjeux (DX/UI) | Matthew (Demo) | Aleksa (Research) | Sicheng (RAG) | Jake (Vercel) |
|---------|:------------:|:---------------:|:-------------:|:--------------:|:-----------------:|:-------------:|:-------------:|
| VoiceCoach | ⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ | ⭐⭐ |
| WebSensei | ⭐ | ⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐ | ⭐⭐ |
| AgentColony | ⭐ | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ |
| TrustLoop | ⭐⭐⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐ | ⭐ |
| ERA-Lite | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐⭐ |
| MemoryForge | ⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ |
| DeployBot | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ | ⭐⭐⭐ |
| GuardianAgent | ⭐⭐⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐ | ⭐ |
| NotebookEvolver | ⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐ |
| Daydreamer-Lite | ⭐ | ⭐ | ⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ |

---

## Demo Strategy

### The 5-Minute Demo Structure

```
1. HOOK (15 seconds)
   "What if [bold claim]?"
   Example: "What if your scrapers could fix themselves?"

2. PROBLEM (30 seconds)
   Show the pain point visually
   Example: Show a broken scraper, frustrated developer

3. SOLUTION (2 minutes)
   Live demo of self-improvement happening
   Example: Break a scraper live, watch it recover

4. METRICS (30 seconds)
   Before/after numbers from Weave
   Example: "95% recovery rate, 3x faster than manual fixes"

5. VISION (15 seconds)
   "This is how [domain] will work in 2 years"
   Example: "This is how web automation will work - resilient by default"
```

### Demo Tips

- **Pre-load data**: Have improvement history ready to show
- **Have a backup**: If live demo fails, have a recorded version
- **Make metrics visible**: Weave dashboards should be open and ready
- **Practice the narrative**: The story matters as much as the tech
- **End with the tagline**: Leave judges with a memorable phrase

---

## Final Recommendations

### If You Want to WIN (Safest Path)

**Build VoiceCoach or WebSensei**
- High demo impact
- Clear sponsor alignment (Daily or Browserbase)
- Appeals to 4+ judges
- Technically impressive but achievable in 24 hours

### If You Want to Make a Statement (Higher Risk, Higher Reward)

**Build AgentColony or ERA-Lite**
- Research-grade ambition
- "Paradigm shift" narrative
- Aleksa + Shadi will love it
- Needs flawless demo preparation

### If You Care About Safety/Production

**Build TrustLoop or GuardianAgent**
- Dex + Allie are strong advocates
- Differentiates from "cool demo" projects
- Shows production mindset

### Multi-Sponsor Prize Strategy

To win BOTH a main prize AND a sponsor prize:

| Main Prize Target | Sponsor Prize | Recommended Project |
|-------------------|---------------|---------------------|
| Grand Prize | Best Use of Daily | VoiceCoach |
| Grand Prize | Best Use of Browserbase | WebSensei |
| Best Self-Improving | Best Use of Weave | ERA-Lite or MemoryForge |
| Runner-up | Best Use of Vercel | DeployBot |
| Runner-up | Best Use of Google Cloud | AgentColony |

---

## Quick Reference: Project Comparison

| Project | Difficulty | Demo Impact | Judge Appeal | Sponsor Fit |
|---------|:----------:|:-----------:|:------------:|:-----------:|
| VoiceCoach | Medium | Very High | Very High | Daily ⭐⭐⭐ |
| WebSensei | Medium | Very High | High | Browserbase ⭐⭐⭐ |
| AgentColony | High | High | High | Google ⭐⭐⭐ |
| TrustLoop | Medium | Medium | High | Redis/Weave ⭐⭐ |
| ERA-Lite | High | High | High | Weave ⭐⭐⭐ |
| MemoryForge | Medium | Medium | Medium | Redis ⭐⭐⭐ |
| DeployBot | Medium | High | Medium | Vercel ⭐⭐⭐ |
| GuardianAgent | Medium | Medium | High | Weave/Redis ⭐⭐ |
| NotebookEvolver | Medium | Medium | Medium | Marimo ⭐⭐⭐ |
| Daydreamer-Lite | Very High | Very High | High | Browserbase ⭐⭐ |

---

## Appendix: Sponsor Prize Criteria

### Best Use of Weave ($1,000 + TRMNL)
- Deep integration with tracing
- Meaningful use of observability for self-improvement
- Dashboard showing agent evolution

### Best Use of Daily/Pipecat
- Real-time voice/audio quality
- Low latency (<500ms)
- Creative use of Pipecat pipeline

### Best Use of Redis
- Vector search for memory/retrieval
- Fast state management
- Meaningful caching strategy

### Best Use of Browserbase
- Reliable web automation
- Creative use of Stagehand
- Self-healing patterns

### Best Use of Vercel
- Edge deployment
- AI SDK integration
- Performance optimization

### Best Use of Google Cloud
- ADK/A2A protocol usage
- Infrastructure sophistication
- Agent-to-agent communication

---

## 5 Additional Novel Project Ideas (Deep Tool Combinations)

These projects focus on NOVEL combinations of sponsor tools that create powerful synergies.

---

### 11. "VoiceNav" - Voice-Controlled Web Agent That Learns Your Patterns

**Tagline:** *"Browse the web with your voice. Watch it get smarter with every command."*

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

#### Sponsor Tools Integration (4 tools)

| Tool | Deep Integration |
|------|------------------|
| **Daily + Pipecat** | Real-time voice input/output. User speaks commands like "Find me the cheapest flight to Tokyo next month." Pipecat handles VAD (voice activity detection), STT, and TTS for natural conversation flow. |
| **Browserbase + Stagehand** | Headless browser executes web actions. Stagehand's `act()` and `extract()` functions translate voice intents into DOM interactions. Browser sessions persist across voice commands. |
| **Weave** | Traces every voice→action→result chain. Logs: intent classification confidence, action success/failure, user corrections, and timing metrics. Creates feedback dataset automatically. |
| **Redis** | Stores action embeddings for similar-command retrieval. Caches successful action sequences per website. Maintains user preference vectors that evolve over session. |

#### Self-Improvement Loop

```
┌─────────────────────────────────────────────────────────────────┐
│                    VOICENAV IMPROVEMENT CYCLE                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   USER VOICE ──► Intent Parser ──► Action Planner ──► Browser  │
│       │              │                   │               │      │
│       │              ▼                   ▼               │      │
│       │         [Weave Trace]      [Redis Cache]        │      │
│       │              │                   │               │      │
│       │              └───────┬───────────┘               │      │
│       │                      ▼                           │      │
│       │              Feedback Collector                  │      │
│       │                      │                           │      │
│       ▼                      ▼                           ▼      │
│   "No, I meant    ◄── Correction ──►  Success/Fail ──► Result  │
│    the OTHER                              │                     │
│    button"                                ▼                     │
│       │                           [Weave Dataset]               │
│       │                                   │                     │
│       └──────────────────────────────────►│                     │
│                                           ▼                     │
│                                   Nightly Fine-tune             │
│                                   (Intent Classifier)           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Feedback Mechanisms:**
1. **Implicit**: Task completion rate, retry count, time-to-success
2. **Explicit**: User corrections ("No, click the blue button")
3. **Behavioral**: Which cached actions get reused vs. regenerated

#### Code Architecture

```python
# main.py - VoiceNav Core
import weave
from daily import Daily
from pipecat import Pipeline, VADAnalyzer, STTService, TTSService
from browserbase import Browserbase
from stagehand import Stagehand
import redis
import json

weave.init("voicenav-agent")

class VoiceNavAgent:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379, decode_responses=True)
        self.browser = Browserbase()
        self.stagehand = Stagehand(self.browser)
        self.voice_pipeline = self._setup_voice()

    def _setup_voice(self):
        return Pipeline([
            VADAnalyzer(),
            STTService(model="whisper-large"),
            self.process_command,  # Our handler
            TTSService(voice="nova")
        ])

    @weave.op()  # Traces this function
    def process_command(self, transcript: str) -> str:
        # Check Redis for similar successful commands
        cached_action = self._find_similar_action(transcript)

        if cached_action and cached_action['confidence'] > 0.85:
            result = self._execute_cached(cached_action)
        else:
            result = self._plan_and_execute(transcript)

        # Log for improvement
        self._log_interaction(transcript, result)
        return result['response']

    @weave.op()
    def _plan_and_execute(self, command: str):
        # Stagehand translates natural language to browser action
        action_plan = self.stagehand.act(command)

        # Execute with observability
        with weave.attributes({'command': command, 'plan': action_plan}):
            result = self.stagehand.extract("What is the result of this action?")

        # Cache successful actions in Redis
        if result['success']:
            embedding = self._embed_command(command)
            self.redis.hset(f"action:{hash(command)}", mapping={
                'command': command,
                'action_plan': json.dumps(action_plan),
                'embedding': embedding.tobytes(),
                'success_count': 1
            })

        return result

    def _find_similar_action(self, command: str):
        """Vector search in Redis for similar past commands"""
        embedding = self._embed_command(command)

        # Redis vector similarity search
        results = self.redis.ft("action_idx").search(
            Query(f"*=>[KNN 3 @embedding $vec AS score]")
            .return_fields("command", "action_plan", "score", "success_count")
            .dialect(2),
            query_params={"vec": embedding.tobytes()}
        )

        if results.docs and float(results.docs[0].score) > 0.85:
            return results.docs[0]
        return None

# voice_handler.py - Daily Integration
from daily import CallClient, Daily

class VoiceHandler:
    def __init__(self, agent: VoiceNavAgent):
        Daily.init()
        self.client = CallClient()
        self.agent = agent

    async def on_audio_received(self, participant_id, audio_data):
        # Pipecat processes audio through pipeline
        response = await self.agent.voice_pipeline.process(audio_data)

        # Send TTS response back through Daily
        await self.client.send_audio(response.audio)
```

#### Demo Script (5 minutes)

| Time | Action | What Judges See |
|------|--------|-----------------|
| 0:00-0:30 | **Hook** | "What if your browser assistant learned YOUR preferences?" Show Weave dashboard with 0 traces. |
| 0:30-1:30 | **First Command** | Say "Find flights to Tokyo for under $800". Watch Stagehand navigate Kayak. Show Weave trace logging the entire chain. Agent stumbles slightly, takes 15 seconds. |
| 1:30-2:30 | **Correction** | "No, sort by price, not duration." Agent corrects. Weave shows correction logged. Redis shows action cached with correction. |
| 2:30-3:30 | **Same Command Later** | Repeat similar command. Agent executes in 3 seconds using cached action. Show Redis hit in logs. "It remembered!" |
| 3:30-4:30 | **Improvement Metrics** | Pull up Weave dashboard: show success rate increasing, average time decreasing, correction frequency dropping. Show the actual training dataset being built. |
| 4:30-5:00 | **Vision** | "Every user interaction makes VoiceNav smarter. Imagine this across thousands of users - a browser that truly understands how humans want to interact with the web." |

#### Why Judges Love This

| Judge Track | Appeal |
|-------------|--------|
| **Daily/Pipecat (Kwindla)** | Novel voice→browser control pipeline. Shows Pipecat's VAD + streaming capabilities in real application. Not just a chatbot! |
| **Browserbase** | Demonstrates Stagehand's natural language action planning with real-world correction handling. |
| **Weave** | Perfect showcase: traces show the FULL journey from voice to DOM click. Correction dataset is gold for fine-tuning. |
| **Redis** | Vector search for action similarity is clever. Shows Redis as semantic cache, not just key-value. |

---

### 12. "AgentSwarm" - Self-Organizing Multi-Agent Research Teams

**Tagline:** *"Agents that hire, fire, and train each other to solve your research questions."*

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

#### Sponsor Tools Integration (4 tools)

| Tool | Deep Integration |
|------|------------------|
| **Google Cloud ADK + A2A** | Agent-to-Agent protocol enables typed message passing between specialized agents. ADK provides the agent runtime. Agents can spawn sub-agents dynamically. |
| **Redis** | Shared memory layer between agents. Vector store for research embeddings. Pub/Sub for real-time agent coordination. Sorted sets track agent performance scores. |
| **Weave** | Traces multi-agent conversations. Logs which agent combinations succeed. Tracks "agent fitness" metrics over time. Enables replay of successful swarm patterns. |
| **Marimo** | Interactive notebook for swarm visualization. Users can see agent hiring/firing decisions live. Modify swarm parameters and see immediate results. |

#### Self-Improvement Loop

```
┌────────────────────────────────────────────────────────────────────┐
│                 AGENTSWARM EVOLUTIONARY CYCLE                      │
├────────────────────────────────────────────────────────────────────┤
│                                                                    │
│  USER QUERY: "What are the emerging trends in quantum computing?"  │
│                              │                                     │
│                              ▼                                     │
│                    ┌─────────────────┐                             │
│                    │  COORDINATOR    │◄──── Weave: logs all        │
│                    │  AGENT (ADK)    │       decisions             │
│                    └────────┬────────┘                             │
│                             │                                      │
│              ┌──────────────┼──────────────┐                       │
│              ▼              ▼              ▼                       │
│       ┌──────────┐   ┌──────────┐   ┌──────────┐                   │
│       │ Scholar  │   │ Analyst  │   │ Writer   │                   │
│       │ Agent    │   │ Agent    │   │ Agent    │                   │
│       │ Score:87 │   │ Score:92 │   │ Score:71 │◄── Low score!     │
│       └────┬─────┘   └────┬─────┘   └────┬─────┘                   │
│            │              │              │                         │
│            └──────────────┼──────────────┘                         │
│                           ▼                                        │
│               ┌───────────────────────┐                            │
│               │  Redis: Shared Memory │                            │
│               │  • Research vectors   │                            │
│               │  • Agent scores       │                            │
│               │  • Pub/Sub messages   │                            │
│               └───────────┬───────────┘                            │
│                           │                                        │
│                           ▼                                        │
│               ┌───────────────────────┐                            │
│               │  SWARM EVOLUTION      │                            │
│               │  • Fire Writer (71)   │                            │
│               │  • Clone Analyst (92) │                            │
│               │  • Mutate prompts     │                            │
│               └───────────────────────┘                            │
│                           │                                        │
│                           ▼                                        │
│               ┌───────────────────────┐                            │
│               │  Marimo Notebook      │                            │
│               │  Live swarm viz       │                            │
│               │  User adjusts params  │                            │
│               └───────────────────────┘                            │
│                                                                    │
└────────────────────────────────────────────────────────────────────┘
```

**Evolutionary Mechanisms:**
1. **Performance Scoring**: Each agent rated on task completion, peer reviews, user feedback
2. **Agent Breeding**: High-performing agent prompts combined to create new agents
3. **Mutation**: Random prompt variations tested against baseline
4. **Natural Selection**: Bottom 20% agents replaced each cycle

#### Code Architecture

```python
# coordinator.py - Google ADK Coordinator Agent
from google.adk import Agent, AgentRuntime
from google.adk.a2a import A2AClient, Message
import weave
import redis
import json

weave.init("agentswarm")

class CoordinatorAgent(Agent):
    def __init__(self):
        super().__init__(name="coordinator")
        self.redis = redis.Redis()
        self.a2a = A2AClient()
        self.active_agents = {}

    @weave.op()
    async def handle_query(self, query: str) -> dict:
        # Decide which agents to spawn based on query type
        agent_team = await self._assemble_team(query)

        # Distribute work via A2A protocol
        tasks = await self._decompose_query(query)

        results = []
        for agent_id, task in zip(agent_team, tasks):
            # A2A typed message passing
            response = await self.a2a.send(
                to=agent_id,
                message=Message(
                    type="research_task",
                    payload={"task": task, "context": self._get_shared_context()}
                )
            )
            results.append(response)

            # Update agent score in Redis
            self._update_agent_score(agent_id, response.quality_score)

        # Synthesize results
        return await self._synthesize(results)

    @weave.op()
    async def _assemble_team(self, query: str) -> list:
        """Select agents based on performance history"""
        # Get agent scores from Redis sorted set
        top_agents = self.redis.zrevrange("agent_scores", 0, 4, withscores=True)

        # Match agents to query requirements
        query_embedding = self._embed(query)

        selected = []
        for agent_id, score in top_agents:
            agent_specialty = self.redis.hget(f"agent:{agent_id}", "specialty_embedding")
            if self._cosine_sim(query_embedding, agent_specialty) > 0.7:
                selected.append(agent_id)

        # If not enough specialists, spawn new agents
        while len(selected) < 3:
            new_agent = await self._spawn_agent(query)
            selected.append(new_agent)

        return selected

    @weave.op()
    async def _evolve_swarm(self):
        """Periodic evolution of agent population"""
        # Get all agent scores
        all_scores = self.redis.zrange("agent_scores", 0, -1, withscores=True)

        # Bottom 20% get replaced
        bottom = all_scores[:len(all_scores)//5]
        top = all_scores[-2:]  # Top 2 performers

        for agent_id, _ in bottom:
            # Breed from top performers
            parent1_prompt = self.redis.hget(f"agent:{top[0][0]}", "system_prompt")
            parent2_prompt = self.redis.hget(f"agent:{top[1][0]}", "system_prompt")

            # Crossover + mutation
            new_prompt = self._crossover_prompts(parent1_prompt, parent2_prompt)
            new_prompt = self._mutate_prompt(new_prompt)

            # Replace underperformer
            self.redis.hset(f"agent:{agent_id}", "system_prompt", new_prompt)
            self.redis.zadd("agent_scores", {agent_id: 50})  # Reset score

            # Log evolution event
            weave.log({"evolution": "replacement", "old_agent": agent_id, "new_prompt": new_prompt})

# specialist_agent.py - Individual Research Agent
class SpecialistAgent(Agent):
    def __init__(self, specialty: str, system_prompt: str):
        super().__init__(name=f"specialist_{specialty}")
        self.specialty = specialty
        self.system_prompt = system_prompt
        self.redis = redis.Redis()

    @weave.op()
    async def handle_message(self, message: Message) -> dict:
        if message.type == "research_task":
            return await self._research(message.payload)
        elif message.type == "peer_review":
            return await self._review_peer(message.payload)

    async def _research(self, payload: dict):
        task = payload["task"]

        # Check Redis for relevant cached research
        cached = self._vector_search_cache(task)

        # Do research (simplified)
        result = await self._llm_research(task, cached_context=cached)

        # Store in shared Redis memory
        self.redis.hset("shared_research", task, json.dumps(result))

        # Publish to other agents
        self.redis.publish("research_updates", json.dumps({
            "agent": self.name,
            "task": task,
            "summary": result["summary"]
        }))

        return result

# marimo_viz.py - Live Swarm Visualization
import marimo as mo

app = mo.App()

@app.cell
def swarm_dashboard():
    import redis
    import weave

    r = redis.Redis()

    # Live agent scores
    scores = r.zrange("agent_scores", 0, -1, withscores=True)

    # Create interactive visualization
    chart = mo.ui.altair_chart(
        alt.Chart(scores_df).mark_bar().encode(
            x='agent_id',
            y='score',
            color=alt.condition(
                alt.datum.score < 50,
                alt.value('red'),
                alt.value('green')
            )
        )
    )

    # Slider to adjust evolution parameters
    mutation_rate = mo.ui.slider(0, 1, value=0.1, label="Mutation Rate")
    selection_pressure = mo.ui.slider(0, 1, value=0.2, label="Selection Pressure")

    return mo.vstack([chart, mutation_rate, selection_pressure])

@app.cell
def evolution_controls(mutation_rate, selection_pressure):
    # These values feed back into the coordinator
    r = redis.Redis()
    r.hset("swarm_params", mapping={
        "mutation_rate": mutation_rate.value,
        "selection_pressure": selection_pressure.value
    })
    return f"Params updated: mutation={mutation_rate.value}, selection={selection_pressure.value}"
```

#### Demo Script (5 minutes)

| Time | Action | What Judges See |
|------|--------|-----------------|
| 0:00-0:30 | **Hook** | "What if AI agents could hire and fire each other?" Show Marimo notebook with empty swarm. |
| 0:30-1:30 | **Query 1** | Submit: "Research the current state of nuclear fusion." Watch 5 agents spawn in real-time. See A2A messages flying between them in Weave trace. |
| 1:30-2:30 | **Scores Update** | One agent performs poorly (score: 45). Marimo shows it turning red. Coordinator "fires" it, breeds replacement from top 2 performers. |
| 2:30-3:30 | **Query 2** | Submit similar query. New bred agent outperforms! Show Weave comparison of Gen1 vs Gen2 agent traces. |
| 3:30-4:30 | **Interactive Evolution** | Use Marimo sliders to crank up mutation rate. Watch swarm rapidly diversify. Show Redis pub/sub message flow. |
| 4:30-5:00 | **Vision** | "This is natural selection for AI. The best agents survive, the worst get replaced. In 10 generations, this swarm went from 60% to 94% accuracy." |

#### Why Judges Love This

| Judge Track | Appeal |
|-------------|--------|
| **Google Cloud** | Perfect A2A showcase - typed messages, agent spawning, ADK runtime. Shows protocol's power for multi-agent coordination. |
| **Weave** | Multi-agent tracing is HARD. This shows it elegantly. Evolution metrics over time = perfect dashboard content. |
| **Redis** | Pub/Sub for agent coordination + Sorted Sets for leaderboard + Vector search for memory = trifecta. |
| **Marimo** | Live visualization of AI evolution. Interactive parameter tuning. This is what notebooks should be. |

---

### 13. "ReflectiveUI" - The Self-Optimizing Interface

**Tagline:** *"A dashboard that rewrites its own code to serve you better."*

**Win Probability: HIGH** ⭐⭐⭐⭐

#### Sponsor Tools Integration (4 tools)

| Tool | Deep Integration |
|------|------------------|
| **Vercel** | AI SDK for React component generation. Edge functions for real-time personalization. Instant deployments for A/B testing variants. |
| **Redis** | Stores user interaction heatmaps. Caches generated component variants. Vector search for similar user patterns. |
| **Weave** | Traces every UI interaction → user satisfaction signal. Logs which generated components perform best. Creates training data for component generator. |
| **Marimo** | Admin notebook for analyzing UI performance. Generates new component variants. Pushes to Vercel via API. |

#### Self-Improvement Loop

```
┌──────────────────────────────────────────────────────────────────┐
│                   REFLECTIVEUI IMPROVEMENT CYCLE                 │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│   USER INTERACTS WITH DASHBOARD                                  │
│            │                                                     │
│            ▼                                                     │
│   ┌─────────────────────────────────────────┐                    │
│   │         Vercel Edge Function            │                    │
│   │   • Tracks clicks, hovers, scrolls      │                    │
│   │   • Measures time-to-task               │                    │
│   │   • Detects rage clicks, confusion      │                    │
│   └─────────────────┬───────────────────────┘                    │
│                     │                                            │
│                     ▼                                            │
│   ┌─────────────────────────────────────────┐                    │
│   │         Weave Interaction Log           │                    │
│   │   {                                     │                    │
│   │     component: "DataTable",             │                    │
│   │     variant: "v3",                      │                    │
│   │     rage_clicks: 3,                     │                    │
│   │     task_completion: false,             │                    │
│   │     frustration_score: 0.8              │                    │
│   │   }                                     │                    │
│   └─────────────────┬───────────────────────┘                    │
│                     │                                            │
│                     ▼                                            │
│   ┌─────────────────────────────────────────┐                    │
│   │         Redis Pattern Store             │                    │
│   │   • User behavior embeddings            │                    │
│   │   • Component performance scores        │                    │
│   │   • A/B test assignments                │                    │
│   └─────────────────┬───────────────────────┘                    │
│                     │                                            │
│                     ▼                                            │
│   ┌─────────────────────────────────────────┐                    │
│   │      Marimo Analysis Notebook           │                    │
│   │   • Identifies underperforming UIs      │                    │
│   │   • Generates improved variants         │                    │
│   │   • Triggers Vercel deployment          │                    │
│   └─────────────────┬───────────────────────┘                    │
│                     │                                            │
│                     ▼                                            │
│   ┌─────────────────────────────────────────┐                    │
│   │      Vercel AI SDK Component Gen        │                    │
│   │   • Generates new React components      │                    │
│   │   • Deploys as new variant              │                    │
│   │   • Routes 10% traffic to test          │                    │
│   └─────────────────────────────────────────┘                    │
│                     │                                            │
│                     ▼                                            │
│              NEW COMPONENT LIVE                                  │
│              (Cycle repeats)                                     │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

#### Code Architecture

```typescript
// app/api/track/route.ts - Vercel Edge Function for Interaction Tracking
import { Redis } from '@upstash/redis'
import Weave from 'weave-js'

const redis = new Redis({ url: process.env.REDIS_URL, token: process.env.REDIS_TOKEN })
const weave = new Weave({ projectName: 'reflective-ui' })

export const runtime = 'edge'

export async function POST(request: Request) {
  const interaction = await request.json()

  // Calculate frustration signals
  const frustrationScore = calculateFrustration(interaction)

  // Log to Weave for ML training
  await weave.log({
    component: interaction.componentId,
    variant: interaction.variant,
    userId: interaction.userId,
    frustrationScore,
    taskCompleted: interaction.taskCompleted,
    timeOnTask: interaction.timeOnTask,
    rageClicks: interaction.rageClicks,
    timestamp: Date.now()
  })

  // Update Redis component scores
  await redis.zincrby(
    `component:${interaction.componentId}:scores`,
    frustrationScore < 0.3 ? 1 : -1,
    interaction.variant
  )

  // Store user pattern for personalization
  const pattern = await embedInteraction(interaction)
  await redis.hset(`user:${interaction.userId}:patterns`, {
    [Date.now()]: JSON.stringify(pattern)
  })

  return Response.json({ success: true })
}

function calculateFrustration(interaction: any): number {
  let score = 0
  if (interaction.rageClicks > 2) score += 0.3
  if (interaction.timeOnTask > 30000) score += 0.2  // 30s threshold
  if (!interaction.taskCompleted) score += 0.3
  if (interaction.backButtonCount > 1) score += 0.2
  return Math.min(score, 1)
}
```

```typescript
// components/AdaptiveDataTable.tsx - Self-Improving Component
'use client'
import { useEffect, useState } from 'react'
import { generateReactComponent } from 'ai/rsc'  // Vercel AI SDK

export function AdaptiveDataTable({ data, userId }) {
  const [variant, setVariant] = useState('default')
  const [CustomComponent, setCustomComponent] = useState(null)

  useEffect(() => {
    // Fetch personalized variant from Redis via API
    async function getPersonalizedVariant() {
      const res = await fetch(`/api/personalize?userId=${userId}&component=DataTable`)
      const { variant, customCode } = await res.json()

      if (customCode) {
        // Dynamically render AI-generated component
        const Component = await generateReactComponent(customCode)
        setCustomComponent(() => Component)
      }
      setVariant(variant)
    }
    getPersonalizedVariant()
  }, [userId])

  // Track all interactions
  const trackInteraction = (event: string, details: any) => {
    fetch('/api/track', {
      method: 'POST',
      body: JSON.stringify({
        componentId: 'DataTable',
        variant,
        userId,
        event,
        ...details,
        timestamp: Date.now()
      })
    })
  }

  if (CustomComponent) {
    return <CustomComponent data={data} onInteraction={trackInteraction} />
  }

  // Default variants
  return (
    <div onMouseMove={(e) => trackInteraction('hover', { x: e.clientX, y: e.clientY })}>
      {variant === 'compact' && <CompactTable data={data} />}
      {variant === 'expanded' && <ExpandedTable data={data} />}
      {variant === 'default' && <DefaultTable data={data} />}
    </div>
  )
}
```

```python
# marimo_ui_optimizer.py - Admin Notebook for UI Evolution
import marimo as mo
import weave
import redis
from openai import OpenAI
import requests

app = mo.App()

@app.cell
def performance_dashboard():
    r = redis.Redis()
    weave_client = weave.init("reflective-ui")

    # Get component performance from Weave
    traces = weave_client.query(
        "SELECT component, variant, AVG(frustrationScore) as avg_frustration, COUNT(*) as interactions "
        "FROM interactions "
        "WHERE timestamp > NOW() - INTERVAL '24 hours' "
        "GROUP BY component, variant"
    )

    # Visualize
    chart = mo.ui.altair_chart(
        alt.Chart(traces).mark_bar().encode(
            x='variant',
            y='avg_frustration',
            color='component',
            tooltip=['interactions']
        ).properties(title="Component Frustration Scores (Lower = Better)")
    )

    return chart

@app.cell
def identify_problems(performance_data):
    # Find components with high frustration
    problems = performance_data[performance_data['avg_frustration'] > 0.5]

    mo.md(f"## {len(problems)} Components Need Improvement")

    return mo.ui.table(problems, selection='single', label="Select component to improve")

@app.cell
def generate_improvement(selected_component):
    if not selected_component:
        return "Select a component above"

    component_id = selected_component['component']
    current_variant = selected_component['variant']

    # Get user feedback patterns from Redis
    r = redis.Redis()
    frustration_patterns = r.hgetall(f"component:{component_id}:feedback")

    # Generate improved component with AI
    client = OpenAI()

    prompt = f"""
    The React component '{component_id}' (variant: {current_variant}) has high user frustration.

    User pain points from tracking data:
    {frustration_patterns}

    Generate an improved React component that:
    1. Addresses the specific frustration patterns
    2. Maintains the same props interface
    3. Includes interaction tracking hooks

    Return only the React component code.
    """

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    new_code = response.choices[0].message.content

    # Preview
    return mo.vstack([
        mo.md("### Generated Improvement"),
        mo.ui.code_editor(new_code, language="typescript"),
        mo.ui.button("Deploy to Vercel", on_click=lambda: deploy_variant(component_id, new_code))
    ])

def deploy_variant(component_id: str, code: str):
    # Deploy new variant via Vercel API
    response = requests.post(
        "https://api.vercel.com/v13/deployments",
        headers={"Authorization": f"Bearer {VERCEL_TOKEN}"},
        json={
            "name": f"reflective-ui-{component_id}-variant",
            "files": [{"file": f"components/{component_id}.tsx", "data": code}],
            "target": "preview"  # A/B test on preview first
        }
    )

    # Store variant in Redis for routing
    r = redis.Redis()
    variant_id = f"v{int(time.time())}"
    r.hset(f"component:{component_id}:variants", variant_id, code)
    r.zadd(f"component:{component_id}:scores", {variant_id: 50})  # Start at neutral

    return f"Deployed {variant_id}! Routing 10% traffic for testing."
```

#### Demo Script (5 minutes)

| Time | Action | What Judges See |
|------|--------|-----------------|
| 0:00-0:30 | **Hook** | "What if your UI could watch users struggle... and fix itself?" Show dashboard with interaction heatmap. |
| 0:30-1:30 | **User Struggles** | Demo user trying to use a clunky data table. Rage clicks visible in real-time Weave trace. Frustration score climbing. |
| 1:30-2:30 | **Marimo Analysis** | Open admin notebook. Show frustration chart. Component highlighted in red. "The system detected the problem." |
| 2:30-3:30 | **Generate & Deploy** | Click "Generate Improvement". AI creates new component. One-click Vercel deploy. Show instant preview URL. |
| 3:30-4:30 | **Immediate Impact** | Route demo user to new variant. Task completion time drops 60%. Show Redis variant scores updating in real-time. |
| 4:30-5:00 | **Vision** | "Every click teaches ReflectiveUI. Every frustration gets fixed. This is UX that evolves." Show 30-day improvement graph. |

#### Why Judges Love This

| Judge Track | Appeal |
|-------------|--------|
| **Vercel (Jake)** | AI SDK for component generation + Edge functions for tracking + instant deployments for A/B = full platform showcase |
| **Redis** | Upstash/Redis powering real-time personalization, variant routing, and pattern storage at edge speed |
| **Weave** | Interaction traces become ML training data. Perfect feedback loop visualization. |
| **Marimo** | Admin notebook that actually DOES something - generates and deploys code. Not just visualization. |

---

### 14. "DebateForge" - Adversarial Agents That Strengthen Arguments

**Tagline:** *"Upload your pitch deck. Get destroyed by AI devil's advocates. Emerge bulletproof."*

**Win Probability: HIGH** ⭐⭐⭐⭐

#### Sponsor Tools Integration (4 tools)

| Tool | Deep Integration |
|------|------------------|
| **Daily + Pipecat** | Real-time voice debate with AI opponents. User practices pitch verbally. Agents interrupt, challenge, push back in real-time voice. |
| **Google Cloud A2A** | Multiple debate agents coordinate attacks. "Skeptical Investor" agent hands off to "Technical Critic" agent seamlessly. |
| **Weave** | Traces every argument → counterargument → user response chain. Identifies which challenges users struggle with most. Builds improvement curriculum. |
| **Vercel** | Beautiful debate arena UI. Real-time transcription display. Argument strength visualizations. Post-debate report generation. |

#### Self-Improvement Loop

```
┌────────────────────────────────────────────────────────────────────┐
│                    DEBATEFORGE IMPROVEMENT CYCLE                   │
├────────────────────────────────────────────────────────────────────┤
│                                                                    │
│  USER UPLOADS PITCH DECK                                           │
│            │                                                       │
│            ▼                                                       │
│  ┌─────────────────────────────────────────────┐                   │
│  │        DEBATE ARENA (Vercel + Daily)        │                   │
│  │                                             │                   │
│  │   ┌─────────────────────────────────────┐   │                   │
│  │   │        ADVERSARIAL AGENTS           │   │                   │
│  │   │         (Google A2A)                │   │                   │
│  │   │                                     │   │                   │
│  │   │  ┌──────────┐    ┌──────────┐       │   │                   │
│  │   │  │Skeptical │◄──►│Technical │       │   │                   │
│  │   │  │Investor  │    │ Critic   │       │   │                   │
│  │   │  └────┬─────┘    └────┬─────┘       │   │                   │
│  │   │       │               │             │   │                   │
│  │   │       └───────┬───────┘             │   │                   │
│  │   │               ▼                     │   │                   │
│  │   │  ┌──────────┐    ┌──────────┐       │   │                   │
│  │   │  │ Market   │◄──►│ Ethics   │       │   │                   │
│  │   │  │ Realist  │    │ Watchdog │       │   │                   │
│  │   │  └──────────┘    └──────────┘       │   │                   │
│  │   └─────────────────────────────────────┘   │                   │
│  │                     │                       │                   │
│  │                     ▼                       │                   │
│  │              USER RESPONDS                  │                   │
│  │              (Voice via Daily)              │                   │
│  └─────────────────────┬───────────────────────┘                   │
│                        │                                           │
│                        ▼                                           │
│  ┌─────────────────────────────────────────────┐                   │
│  │              WEAVE ANALYSIS                 │                   │
│  │                                             │                   │
│  │  • Response quality score                   │                   │
│  │  • Confidence in voice (hesitation detect)  │                   │
│  │  • Argument completeness                    │                   │
│  │  • Recovery time after challenge            │                   │
│  └─────────────────────┬───────────────────────┘                   │
│                        │                                           │
│                        ▼                                           │
│  ┌─────────────────────────────────────────────┐                   │
│  │           ADAPTIVE CURRICULUM               │                   │
│  │                                             │                   │
│  │  User struggles with market size questions  │                   │
│  │  → Next session: 70% market challenges      │                   │
│  │  → Agents get MORE aggressive on markets    │                   │
│  │  → Training material suggested              │                   │
│  └─────────────────────────────────────────────┘                   │
│                                                                    │
│  ════════════════════════════════════════════════                  │
│                                                                    │
│  AGENT SELF-IMPROVEMENT (Parallel Loop):                           │
│                                                                    │
│  • Track which challenges stump users most                         │
│  • Agents learn better attack strategies                           │
│  • "Skeptical Investor" gets sharper over time                     │
│  • New challenge patterns mined from Weave data                    │
│                                                                    │
└────────────────────────────────────────────────────────────────────┘
```

#### Code Architecture

```python
# debate_coordinator.py - Multi-Agent Debate System
from google.adk import Agent, AgentRuntime
from google.adk.a2a import A2AClient, Message
from daily import CallClient, Daily
from pipecat import Pipeline, VAD, STT, TTS
import weave

weave.init("debateforge")

class DebateCoordinator:
    def __init__(self):
        self.a2a = A2AClient()
        self.agents = {
            "skeptical_investor": SkepticalInvestorAgent(),
            "technical_critic": TechnicalCriticAgent(),
            "market_realist": MarketRealistAgent(),
            "ethics_watchdog": EthicsWatchdogAgent()
        }
        self.voice = DailyVoiceHandler()
        self.current_attacker = None

    @weave.op()
    async def start_debate(self, pitch_deck: dict, user_session: str):
        """Initialize debate with pitch context"""
        # Distribute pitch to all agents
        for agent_id, agent in self.agents.items():
            await self.a2a.send(
                to=agent_id,
                message=Message(type="context", payload={"pitch": pitch_deck})
            )

        # Start voice connection
        await self.voice.connect(user_session)

        # Begin with opening challenge
        self.current_attacker = "skeptical_investor"
        opening = await self.a2a.send(
            to=self.current_attacker,
            message=Message(type="opening_challenge", payload={})
        )

        # Speak challenge
        await self.voice.speak(opening.content)

    @weave.op()
    async def handle_user_response(self, audio_data: bytes):
        """Process user's spoken response"""
        # Transcribe
        transcript = await self.voice.transcribe(audio_data)

        # Analyze response quality
        analysis = self._analyze_response(transcript)

        # Log to Weave for improvement tracking
        weave.log({
            "user_response": transcript,
            "challenge_from": self.current_attacker,
            "response_quality": analysis.quality_score,
            "confidence_markers": analysis.confidence,
            "hesitation_detected": analysis.hesitations,
            "argument_coverage": analysis.coverage
        })

        # Decide next move via A2A coordination
        next_action = await self._coordinate_next_challenge(transcript, analysis)

        if next_action["type"] == "handoff":
            # Agent hands off to specialist
            self.current_attacker = next_action["to_agent"]

        elif next_action["type"] == "escalate":
            # Same agent gets more aggressive
            pass

        elif next_action["type"] == "acknowledge":
            # Good response, move to next topic
            pass

        # Get next challenge
        challenge = await self.a2a.send(
            to=self.current_attacker,
            message=Message(
                type="generate_challenge",
                payload={
                    "user_response": transcript,
                    "analysis": analysis.dict(),
                    "instruction": next_action["instruction"]
                }
            )
        )

        await self.voice.speak(challenge.content)

    async def _coordinate_next_challenge(self, response: str, analysis):
        """A2A coordination between agents"""
        # Broadcast response to all agents
        votes = []
        for agent_id, agent in self.agents.items():
            vote = await self.a2a.send(
                to=agent_id,
                message=Message(
                    type="vote_next_action",
                    payload={"response": response, "analysis": analysis.dict()}
                )
            )
            votes.append({"agent": agent_id, "vote": vote})

        # Consensus mechanism
        return self._resolve_votes(votes)

# adversarial_agent.py - Individual Debate Agent
class SkepticalInvestorAgent(Agent):
    def __init__(self):
        super().__init__(name="skeptical_investor")
        self.personality = """
        You are a skeptical venture investor who has seen thousands of pitches fail.
        You challenge market assumptions, question unit economics, and demand evidence.
        Be tough but fair. Your goal is to strengthen the founder's pitch.
        """
        self.attack_patterns = []  # Learned from Weave data

    @weave.op()
    async def generate_challenge(self, payload: dict) -> str:
        user_response = payload["user_response"]
        analysis = payload["analysis"]
        instruction = payload["instruction"]

        # Check Weave for challenges that historically stump users
        effective_challenges = weave.query(
            "SELECT challenge_text FROM debates "
            "WHERE response_quality < 0.3 AND agent = 'skeptical_investor' "
            "ORDER BY timestamp DESC LIMIT 10"
        )

        prompt = f"""
        {self.personality}

        User's response: {user_response}
        Analysis: {analysis}
        Instruction: {instruction}

        Historically effective challenges:
        {effective_challenges}

        Generate a pointed follow-up challenge. Be specific.
        If they dodged, call it out. If they were vague, demand specifics.
        """

        challenge = await self.llm.generate(prompt)
        return challenge
```

```typescript
// app/debate/page.tsx - Vercel Frontend
'use client'
import { useState, useEffect } from 'react'
import DailyIframe from '@daily-co/daily-js'

export default function DebateArena() {
  const [transcript, setTranscript] = useState<Message[]>([])
  const [argumentStrength, setArgumentStrength] = useState<number[]>([])
  const [currentChallenger, setCurrentChallenger] = useState('')

  useEffect(() => {
    // Connect to Daily room
    const daily = DailyIframe.createCallObject()
    daily.join({ url: roomUrl })

    // Real-time transcript updates via WebSocket
    const ws = new WebSocket(process.env.NEXT_PUBLIC_WS_URL)
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data)
      if (data.type === 'transcript') {
        setTranscript(prev => [...prev, data.message])
      }
      if (data.type === 'analysis') {
        setArgumentStrength(prev => [...prev, data.score])
      }
      if (data.type === 'challenger_change') {
        setCurrentChallenger(data.agent)
      }
    }
  }, [])

  return (
    <div className="grid grid-cols-3 gap-4 h-screen p-4">
      {/* Agent Panel */}
      <div className="col-span-1 bg-gray-900 rounded-lg p-4">
        <h2 className="text-xl font-bold mb-4">Adversaries</h2>
        <AgentCard
          name="Skeptical Investor"
          active={currentChallenger === 'skeptical_investor'}
          icon="$"
        />
        <AgentCard
          name="Technical Critic"
          active={currentChallenger === 'technical_critic'}
          icon="<>"
        />
        <AgentCard
          name="Market Realist"
          active={currentChallenger === 'market_realist'}
          icon="#"
        />
        <AgentCard
          name="Ethics Watchdog"
          active={currentChallenger === 'ethics_watchdog'}
          icon="!"
        />
      </div>

      {/* Debate Transcript */}
      <div className="col-span-1 bg-gray-800 rounded-lg p-4 overflow-y-auto">
        <h2 className="text-xl font-bold mb-4">Live Debate</h2>
        {transcript.map((msg, i) => (
          <TranscriptBubble
            key={i}
            speaker={msg.speaker}
            text={msg.text}
            strength={argumentStrength[i]}
          />
        ))}
      </div>

      {/* Real-time Analysis */}
      <div className="col-span-1 bg-gray-800 rounded-lg p-4">
        <h2 className="text-xl font-bold mb-4">Live Analysis</h2>
        <ArgumentStrengthChart data={argumentStrength} />
        <WeaknessHeatmap challenges={transcript.filter(m => m.speaker !== 'user')} />
        <ImprovementSuggestions />
      </div>
    </div>
  )
}
```

#### Demo Script (5 minutes)

| Time | Action | What Judges See |
|------|--------|-----------------|
| 0:00-0:30 | **Hook** | "Founders practice pitches on friends who say 'looks great!' Let's try something different." Upload sample pitch deck. |
| 0:30-1:30 | **Opening Challenge** | Skeptical Investor agent speaks (Daily voice): "Your TAM calculation assumes 100% market penetration in 3 years. Walk me through that." User responds verbally, hesitates. |
| 1:30-2:30 | **Agent Handoff** | Technical Critic interrupts (A2A handoff): "And while we're at it, your architecture diagram shows a single point of failure here..." Show agent switching in UI. |
| 2:30-3:30 | **Live Analysis** | Weave dashboard shows response quality dipping. Highlight "market size" as weakness. Show agents learning to press harder on this topic. |
| 3:30-4:30 | **User Improves** | User gives stronger answer on second challenge. Show argument strength chart climbing. Agents acknowledge and move to next topic. |
| 4:30-5:00 | **Post-Debate Report** | Show generated report: "You struggled with market questions. Here are 3 resources and 5 practice questions." Show improvement over multiple sessions. |

#### Why Judges Love This

| Judge Track | Appeal |
|-------------|--------|
| **Daily/Pipecat (Kwindla)** | Voice AI in ADVERSARIAL role - not assistant, opponent! Real-time interruptions. Novel use case. |
| **Google Cloud** | A2A for agent coordination during debate. Handoffs are seamless. Shows protocol handling complex multi-turn scenarios. |
| **Weave** | Debate traces are gold for understanding human-AI interaction patterns. Weakness identification is powerful. |
| **Vercel (Jake)** | Beautiful real-time debate UI with live analysis. Shows AI SDK + streaming capabilities. |

---

### 15. "ContextHarvester" - The Web-Scraping Memory System That Grows Itself

**Tagline:** *"Tell it once what matters. It builds your knowledge base while you sleep."*

**Win Probability: HIGH** ⭐⭐⭐⭐

#### Sponsor Tools Integration (4 tools)

| Tool | Deep Integration |
|------|------------------|
| **Browserbase + Stagehand** | Autonomous web navigation to harvest information. Stagehand's `extract()` pulls structured data. Sessions resume across runs. |
| **Redis** | Vector store for harvested knowledge. Priority queue for URLs to crawl. Deduplication cache. Embedding similarity for relevance scoring. |
| **Weave** | Traces every harvest decision. Logs relevance scores over time. Identifies which sources yield best information. Enables harvest strategy improvement. |
| **Marimo** | User configures harvest preferences. Reviews and rates harvested content. Provides feedback that improves targeting. |

#### Self-Improvement Loop

```
┌─────────────────────────────────────────────────────────────────────┐
│                CONTEXTHARVESTER IMPROVEMENT CYCLE                   │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  USER DEFINES INTEREST: "I need to track AI infrastructure trends"  │
│                              │                                      │
│                              ▼                                      │
│  ┌────────────────────────────────────────────┐                     │
│  │        MARIMO CONFIGURATION NOTEBOOK       │                     │
│  │                                            │                     │
│  │  • Define topic embeddings                 │                     │
│  │  • Set quality thresholds                  │                     │
│  │  • Specify source preferences              │                     │
│  │  • Review harvested content                │                     │
│  └──────────────────────┬─────────────────────┘                     │
│                         │                                           │
│                         ▼                                           │
│  ┌────────────────────────────────────────────┐                     │
│  │          HARVEST SCHEDULER (Redis)         │                     │
│  │                                            │                     │
│  │  Priority Queue:                           │                     │
│  │  1. news.ycombinator.com (score: 0.95)     │                     │
│  │  2. arxiv.org/cs.AI (score: 0.91)          │                     │
│  │  3. blog.google.ai (score: 0.88)           │                     │
│  └──────────────────────┬─────────────────────┘                     │
│                         │                                           │
│                         ▼                                           │
│  ┌────────────────────────────────────────────┐                     │
│  │     BROWSERBASE HARVESTER (Stagehand)      │                     │
│  │                                            │                     │
│  │  for each url in queue:                    │                     │
│  │    navigate(url)                           │                     │
│  │    content = stagehand.extract(            │                     │
│  │      "articles about AI infrastructure"    │                     │
│  │    )                                       │                     │
│  │    links = stagehand.extract(              │                     │
│  │      "links to related content"            │                     │
│  │    )                                       │                     │
│  │    → add relevant links to Redis queue     │                     │
│  └──────────────────────┬─────────────────────┘                     │
│                         │                                           │
│                         ▼                                           │
│  ┌────────────────────────────────────────────┐                     │
│  │           RELEVANCE FILTER (Weave)         │                     │
│  │                                            │                     │
│  │  • Score content vs topic embedding        │                     │
│  │  • Track source quality over time          │                     │
│  │  • Log harvest decisions                   │                     │
│  │  • Build training data for filters         │                     │
│  └──────────────────────┬───────────────────────┘                   │
│                         │                                           │
│           ┌─────────────┴─────────────┐                             │
│           ▼                           ▼                             │
│  ┌────────────────┐         ┌─────────────────┐                     │
│  │ REDIS VECTOR   │         │ DISCARDED       │                     │
│  │ KNOWLEDGE BASE │         │ (logged in Weave│                     │
│  │                │         │  for learning)  │                     │
│  │ • embeddings   │         └─────────────────┘                     │
│  │ • metadata     │                                                 │
│  │ • source info  │                                                 │
│  └───────┬────────┘                                                 │
│          │                                                          │
│          ▼                                                          │
│  ┌────────────────────────────────────────────┐                     │
│  │         USER FEEDBACK (Marimo)             │                     │
│  │                                            │                     │
│  │  "This article was great" → boost source   │                     │
│  │  "This is off-topic" → penalize source     │                     │
│  │  "Find more like this" → expand query      │                     │
│  └──────────────────────┬─────────────────────┘                     │
│                         │                                           │
│                         ▼                                           │
│  ┌────────────────────────────────────────────┐                     │
│  │        STRATEGY OPTIMIZER (Weave)          │                     │
│  │                                            │                     │
│  │  Analyze: Which sources yield kept content?│                     │
│  │  Learn: Adjust relevance thresholds        │                     │
│  │  Evolve: Reorder priority queue            │                     │
│  │  Expand: Discover new valuable sources     │                     │
│  └────────────────────────────────────────────┘                     │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

#### Code Architecture

```python
# harvester.py - Core Harvest Engine
from browserbase import Browserbase
from stagehand import Stagehand
import redis
import weave
import numpy as np
from sentence_transformers import SentenceTransformer

weave.init("context-harvester")

class ContextHarvester:
    def __init__(self, topic_description: str):
        self.redis = redis.Redis()
        self.browser = Browserbase()
        self.stagehand = Stagehand(self.browser)
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.topic_embedding = self.embedder.encode(topic_description)

    @weave.op()
    async def harvest_cycle(self):
        """Single harvest iteration"""
        # Get highest priority URL from Redis
        url_data = self.redis.zpopmax("harvest_queue")
        if not url_data:
            return None

        url, priority = url_data[0]

        # Navigate and extract
        await self.browser.goto(url)

        content = await self.stagehand.extract(
            f"Extract all articles, posts, or content relevant to: {self.topic_description}. "
            "Return structured data with title, summary, date, and full text."
        )

        # Extract links for queue expansion
        links = await self.stagehand.extract(
            "Find all links to related articles, papers, or discussions. "
            "Return URLs with brief descriptions of what they likely contain."
        )

        # Score and store content
        results = []
        for item in content:
            relevance = self._score_relevance(item)

            weave.log({
                "source": url,
                "item_title": item.get("title"),
                "relevance_score": relevance,
                "decision": "keep" if relevance > 0.7 else "discard"
            })

            if relevance > 0.7:
                # Store in Redis vector DB
                embedding = self.embedder.encode(item["text"])
                item_id = self._store_knowledge(item, embedding, relevance)
                results.append(item_id)

        # Add discovered links to queue with predicted priority
        for link in links:
            predicted_relevance = self._predict_link_relevance(link)
            if predicted_relevance > 0.5:
                self.redis.zadd("harvest_queue", {link["url"]: predicted_relevance})

        # Update source reputation
        self._update_source_score(url, len(results), len(content))

        return results

    @weave.op()
    def _score_relevance(self, item: dict) -> float:
        """Score content relevance to topic"""
        text_embedding = self.embedder.encode(item["text"][:2000])
        similarity = np.dot(self.topic_embedding, text_embedding) / (
            np.linalg.norm(self.topic_embedding) * np.linalg.norm(text_embedding)
        )

        # Boost based on source reputation
        source_score = float(self.redis.zscore("source_reputation", item.get("source", "unknown")) or 0.5)

        return (similarity * 0.7) + (source_score * 0.3)

    def _store_knowledge(self, item: dict, embedding: np.ndarray, relevance: float):
        """Store in Redis vector database"""
        item_id = f"knowledge:{hash(item['title'])}"

        # Check for duplicates via vector similarity
        existing = self.redis.ft("knowledge_idx").search(
            Query(f"*=>[KNN 1 @embedding $vec AS score]").dialect(2),
            query_params={"vec": embedding.tobytes()}
        )

        if existing.docs and float(existing.docs[0].score) > 0.95:
            # Duplicate detected, skip
            weave.log({"action": "duplicate_detected", "existing": existing.docs[0].id})
            return None

        # Store with embedding
        self.redis.hset(item_id, mapping={
            "title": item["title"],
            "text": item["text"],
            "source": item.get("source"),
            "date": item.get("date"),
            "relevance": relevance,
            "embedding": embedding.tobytes(),
            "harvested_at": time.time()
        })

        return item_id

    def _update_source_score(self, url: str, kept: int, total: int):
        """Update source reputation based on harvest quality"""
        domain = urlparse(url).netloc

        if total > 0:
            quality_ratio = kept / total
            # Exponential moving average
            current = float(self.redis.zscore("source_reputation", domain) or 0.5)
            new_score = (current * 0.8) + (quality_ratio * 0.2)
            self.redis.zadd("source_reputation", {domain: new_score})

# strategy_optimizer.py - Learn from harvest patterns
class HarvestStrategyOptimizer:
    def __init__(self):
        self.weave_client = weave.init("context-harvester")
        self.redis = redis.Redis()

    @weave.op()
    def optimize(self):
        """Analyze Weave logs and improve harvest strategy"""
        # Query harvest decisions
        decisions = self.weave_client.query("""
            SELECT source, decision, relevance_score, timestamp
            FROM harvests
            WHERE timestamp > NOW() - INTERVAL '7 days'
        """)

        # Find underperforming sources
        source_stats = decisions.groupby("source").agg({
            "decision": lambda x: (x == "keep").mean(),  # keep rate
            "relevance_score": "mean"
        })

        # Demote poor sources
        for source, stats in source_stats.iterrows():
            if stats["decision"] < 0.2:  # Less than 20% keep rate
                current = self.redis.zscore("harvest_queue", source) or 0
                self.redis.zadd("harvest_queue", {source: current * 0.5})
                weave.log({"action": "demote_source", "source": source, "reason": "low_keep_rate"})

        # Find promising new sources from kept content
        kept_content = self.weave_client.query("""
            SELECT DISTINCT source FROM harvests WHERE decision = 'keep'
        """)

        # Discover linked sources not yet in queue
        # (This feeds back into the harvest loop)
```

```python
# marimo_dashboard.py - User Configuration & Feedback
import marimo as mo
import redis
import weave

app = mo.App()

@app.cell
def topic_configuration():
    topic = mo.ui.text_area(
        label="What do you want to track?",
        value="AI infrastructure, GPU clusters, training optimization, inference serving"
    )

    quality_threshold = mo.ui.slider(
        0.5, 1.0, value=0.7,
        label="Relevance threshold (higher = stricter)"
    )

    return mo.vstack([topic, quality_threshold])

@app.cell
def harvest_status():
    r = redis.Redis()

    # Queue size
    queue_size = r.zcard("harvest_queue")

    # Knowledge base size
    knowledge_count = r.dbsize()  # Approximate

    # Top sources
    top_sources = r.zrevrange("source_reputation", 0, 9, withscores=True)

    return mo.vstack([
        mo.md(f"### Harvest Status"),
        mo.md(f"**Queue:** {queue_size} URLs pending"),
        mo.md(f"**Knowledge Base:** ~{knowledge_count} items"),
        mo.md("**Top Sources:**"),
        mo.ui.table(pd.DataFrame(top_sources, columns=["Source", "Score"]))
    ])

@app.cell
def review_harvested():
    r = redis.Redis()

    # Get recent harvests
    recent = []
    for key in r.scan_iter("knowledge:*", count=20):
        item = r.hgetall(key)
        recent.append({
            "id": key,
            "title": item["title"],
            "source": item["source"],
            "relevance": float(item["relevance"])
        })

    table = mo.ui.table(
        pd.DataFrame(recent),
        selection="multiple",
        label="Review recent harvests"
    )

    feedback_buttons = mo.ui.button_group([
        ("Relevant [+]", "positive"),
        ("Not relevant [-]", "negative"),
        ("More like this [*]", "expand")
    ])

    return mo.vstack([table, feedback_buttons])

@app.cell
def process_feedback(review_table, feedback_buttons):
    if feedback_buttons.value and review_table.value:
        r = redis.Redis()
        weave_client = weave.init("context-harvester")

        for item in review_table.value:
            if feedback_buttons.value == "positive":
                # Boost source reputation
                source = item["source"]
                r.zincrby("source_reputation", 0.1, source)
                weave.log({"feedback": "positive", "item": item["id"], "source": source})

            elif feedback_buttons.value == "negative":
                # Penalize source
                source = item["source"]
                r.zincrby("source_reputation", -0.15, source)
                weave.log({"feedback": "negative", "item": item["id"], "source": source})

            elif feedback_buttons.value == "expand":
                # Find similar and add to high priority queue
                embedding = r.hget(item["id"], "embedding")
                # ... vector search for similar, add to queue

        return f"Processed feedback for {len(review_table.value)} items"
```

#### Demo Script (5 minutes)

| Time | Action | What Judges See |
|------|--------|-----------------|
| 0:00-0:30 | **Hook** | "I need to stay on top of AI infrastructure trends. But I don't have time to read 50 sites daily." Show empty knowledge base. |
| 0:30-1:30 | **Configure** | In Marimo: type topic, set threshold, add seed URLs (HackerNews, ArXiv). Click "Start Harvesting". |
| 1:30-2:30 | **Watch Harvest** | Split screen: Browserbase browser navigating HN → Weave traces showing extraction → Redis queue growing. "It's discovering new sources on its own." |
| 2:30-3:30 | **Quality Learning** | Show source reputation scores. One source has low keep rate. "Watch it deprioritize this source automatically." Queue reorders in real-time. |
| 3:30-4:30 | **User Feedback** | Review 5 articles in Marimo. Mark 2 as "not relevant". Source gets penalized. Mark 1 as "more like this". See related articles get boosted in queue. |
| 4:30-5:00 | **Vision** | "After a week, this knows exactly what matters to me. It finds articles I would have missed. It's my personal research assistant that never sleeps." Show 7-day growth chart. |

#### Why Judges Love This

| Judge Track | Appeal |
|-------------|--------|
| **Browserbase** | Autonomous web crawling with intelligent extraction. Shows Stagehand's power beyond single-page interaction. |
| **Redis** | Vector search + Priority queue + Reputation scores = sophisticated data layer. Perfect Redis use case. |
| **Weave** | Harvest decision logging enables strategy optimization. Clear feedback loop for improvement. |
| **Marimo** | User control panel that ACTUALLY affects system behavior. Interactive feedback improves harvesting. |

---

## Summary: New Project Tool Combinations

| Project | Daily | Browser | Weave | Redis | Vercel | Marimo | Google |
|---------|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|
| **VoiceNav** | X | X | X | X | | | |
| **AgentSwarm** | | | X | X | | X | X |
| **ReflectiveUI** | | | X | X | X | X | |
| **DebateForge** | X | | X | | X | | X |
| **ContextHarvester** | | X | X | X | | X | |

## Key Differentiators from Standard Projects

1. **VoiceNav**: Voice→browser is novel. Not another chatbot.
2. **AgentSwarm**: Agents that EVOLVE, not just cooperate.
3. **ReflectiveUI**: Code that rewrites itself based on user behavior.
4. **DebateForge**: Adversarial AI - it fights you to help you.
5. **ContextHarvester**: Passive intelligence gathering that improves overnight.

Each project demonstrates **self-improvement** as the core mechanism, not just a feature.

---

*Good luck at WeaveHacks! Remember: the winning project combines technical depth with polished UX while addressing safety concerns. Make judges say: "That's impressive, I could actually use that, and I'd trust it in production."*
