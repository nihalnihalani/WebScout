# WeaveHacks Project Ideas & Strategy Guide

> **Event:** WeaveHacks - Self-Improving Agents Hackathon
> **Date:** January 31 - February 1, 2025
> **Location:** Weights & Biases SF Office
> **Prize Pool:** $15k+ including Unitree G2 Pro Robot Dog

---

## Table of Contents

1. [Previous Winning Projects Analysis](#previous-winning-projects-analysis)
2. [Winning Patterns](#winning-patterns)
3. [Judge Profiles & Preferences](#judge-profiles--preferences)
4. [Sponsor Tools Overview](#sponsor-tools-overview)
5. [Top 10 Project Ideas](#top-10-project-ideas)
6. [Judge-Optimized Strategy Matrix](#judge-optimized-strategy-matrix)
7. [Demo Strategy](#demo-strategy)
8. [Final Recommendations](#final-recommendations)

---

## Previous Winning Projects Analysis

### WeaveHacks 2 Winners (Self-Improving Agents Theme)

| Project | What It Did | Why It Won |
|---------|-------------|------------|
| **Daydreamer** | "GPT moment for robotics" - pretrain on video, imagine solutions, act, learn | Ambitious vision + clear improvement loop |
| **ReviveAgent** | Self-improving AI that resolves conflicts, refactors code, eliminates tech debt | Solves real developer pain |
| **The Convergence** | Agents that improve through experience, collaboration, evolution | Multi-agent + emergent behavior |
| **Silicon Valhalla** | Self-learning agent that injects up-to-date documentation into code agents | Addresses knowledge cutoffs |
| **Popstar** | Automating RL reward design for video games using LLMs | RL + LLMs combination |
| **SynErgi** | Self-evolving grid optimizer with GRPO RL | Real-world critical systems |
| **ContentEngine** | Self-improving content generation with agentic memory and RL | Memory + RL integration |
| **AVAX** | AI social media team that hires/fires its own agents | Accountability + self-management |
| **CO-DREAMER** | Knowledge graph generation with iterative RL for factual reasoning | Memory + RL for reasoning |
| **ERA** | Self-improving AI that builds other AIs | Meta-level: AI creating AI |
| **Product Mate** | User meetings to measurable impact automation | Practical workflow automation |

### WeaveHacks 1 Notable Projects

- **Deep Slack**: GPT Deep Research in Slack with scheduled reports
- **MCP-Powered Funnels**: OAuth-enabled MCP servers for DevTools
- **Voice-Control-Browser**: Hands-free web browsing
- **Research Lab Assistant**: Hands-free logging, real-time monitoring
- **Gyrus**: Agentic browser for critical thinking
- **RoboWeave**: Prompt-based multimodal control of embodied agents

---

## Winning Patterns

### The Winning Formula

```
WINNING PROJECT =
    (RL/Feedback Loop)
  + (Multi-Agent OR Memory System)
  + (Visible self-improvement in demo)
  + (Ambitious "paradigm shift" framing)
```

### Technical Patterns That Won

| Pattern | Frequency | Examples |
|---------|-----------|----------|
| **Reinforcement Learning** | 45% of winners | Daydreamer, Popstar, SynErgi, ContentEngine, CO-DREAMER |
| **Multi-Agent Systems** | 36% of winners | The Convergence, SynErgi, AVAX, ERA |
| **Memory Systems** | 27% of winners | ContentEngine, Silicon Valhalla, CO-DREAMER |

### Problem Domains That Won

```
Robotics/Embodied AI:    ███████████████  27% (3 projects)
Developer Tools:         ███████████████  27% (3 projects)
Content/Social:          ██████████       18% (2 projects)
Infrastructure/Energy:   █████            9%  (1 project)
Gaming:                  █████            9%  (1 project)
Product/Business:        █████            9%  (1 project)
```

### What Made Projects Stand Out

1. **Memorable Taglines**
   - "GPT moment for robotics" (Daydreamer)
   - "AI that hires/fires its own agents" (AVAX)
   - "Agents that build other AIs" (ERA)

2. **Closed-Loop Demonstrations**
   - Not just "AI does X" but "AI does X, evaluates, improves, does X better"
   - Visible iteration during demo time

3. **Ambitious but Grounded**
   - Big vision + working prototype

### Self-Improvement Mechanisms That Won

| Type | Projects | Description |
|------|----------|-------------|
| **Experience-Based** | Daydreamer, The Convergence, ContentEngine | Learn from interactions |
| **Generation-Based** | ERA, AVAX | Create new agents/code |
| **Optimization-Based** | Popstar, SynErgi, ReviveAgent | Refine existing solutions |

---

## Judge Profiles & Preferences

### Judges Who Favor Technical Depth

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Aleksa Gordic** | Ex-DeepMind, AI Epiphany YouTube | Research-grade implementations, novel architectures |
| **Lucas Atkins** | CTO at Arcee AI | Fine-tuning, model optimization, enterprise applications |
| **Shadi Saba** | CoreWeave, ex-AWS Neuron | Distributed systems, infrastructure, scale |

### Judges Who Favor Polish + Practicality

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Ray Fernando** | 12-year ex-Apple engineer | Apple-level UX, polished apps |
| **Vjeux** | Meta, React Native, Excalidraw creator | Beautiful UI, clean code, developer tools |
| **Jake Phelps** | Head of DevRel at Vercel | Frontend, deployment, developer experience |
| **Matthew Berman** | AI YouTuber, CodeRabbit | Demo-able projects, clear before/after |
| **Kwindla Kramer** | CEO of Daily, creator of Pipecat | Real-time voice/audio done well |

### Judges Who Favor Safety + Reliability

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Dex Horthy** | Founder of HumanLayer, "12 Factor Agents" | Human-in-the-loop, production safety |
| **Allie Howe** | "Insecure Agents" podcast | Agent security, adversarial robustness |
| **Karan Vaidya** | Co-founder of Composio | Secure tool integrations, SaaS automation |

### Other Notable Judges

| Judge | Background | What Impresses Them |
|-------|------------|---------------------|
| **Sicheng Pan** | Technical Staff at Chroma | RAG, embeddings, memory systems |
| **Ivan Porollo** | Founder of Cerebral Valley | Community potential, go-to-market vision |

---

## Sponsor Tools Overview

### Available Tools & Their Strengths

| Sponsor | Tool | Key Capability | Best Use Case |
|---------|------|----------------|---------------|
| **Weights & Biases** | Weave | LLM tracing & observability | Track agent decisions, visualize improvement |
| **Redis** | Redis Cloud | Vector search, caching, fast memory | Memory systems, session state, similarity search |
| **Browserbase** | Browserbase + Stagehand | Web automation | Browser automation, web scraping, testing |
| **Vercel** | Vercel Platform | Frontend deployment | Instant deployment, edge functions, AI SDK |
| **Daily** | Daily + Pipecat | Real-time video/audio | Voice agents, real-time conversation |
| **Marimo** | Marimo Notebooks | Reproducible AI workflows | Interactive notebooks, sharing |
| **Google Cloud** | ADK + A2A | Agent development & communication | Agent-to-agent protocols, model serving |

---

## Top 10 Project Ideas

### 1. "VoiceCoach" - Real-Time Speech Improvement Agent

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Daily + Pipecat (voice AI), Weave (track improvement) |
| **Self-Improvement** | Learns which coaching tips actually help each user improve |
| **Demo Power** | Judge speaks → gets real-time feedback → sounds better in 60 seconds |
| **Target Judges** | Kwindla (Daily), Ray (UX), Matthew (demo-able) |

**Concept:**
A voice AI that helps users improve their public speaking by analyzing speech patterns in real-time and adapting its coaching style based on what feedback actually helps each user improve.

**Self-Improvement Mechanism:**
```python
class AdaptiveCoachPipeline(Pipeline):
    async def process_audio(self, frame: AudioFrame):
        metrics = analyze_speech(frame)  # Pace, fillers, clarity

        if needs_intervention(metrics):
            tip = select_tip(
                user_profile=self.user_learning_history,
                current_metrics=metrics
            )
            await self.speak(tip)

            # Self-improvement: track if tip worked
            asyncio.create_task(
                self.measure_improvement(tip.id, delay=30)
            )
```

**Why It Wins:**
- Real-time voice is technically hard - doing it smoothly proves competence
- Personalization through self-improvement is the killer feature
- Daily's infrastructure handles the hard parts (WebRTC, scaling)
- Perfect for live demo - judge actually gets better at speaking

**24-Hour Build Plan:**
1. Set up Pipecat pipeline with Daily
2. Implement 3 speech metrics (filler words, pace, volume)
3. Build tip selection with effectiveness tracking
4. Create simple UI showing improvement over time
5. Polish the voice responses

---

### 2. "WebSensei" - Self-Correcting Web Automation

**Win Probability: VERY HIGH** ⭐⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Browserbase + Stagehand |
| **Self-Improvement** | Automatically fixes broken scrapers, learns fallback patterns |
| **Demo Power** | "This scraper broke. WebSensei fixed it automatically." |
| **Target Judges** | Vjeux (DX), Matthew (demo), Jake (frontend) |

**Concept:**
A web scraping agent that detects when websites change structure, automatically fixes its own selectors, and builds resilience over time by learning patterns.

**Self-Improvement Mechanism:**
```typescript
const stagehand = new Stagehand({ browserbaseSessionID });

async function resilientScrape(url: string, target: string) {
  try {
    return await stagehand.extract({ instruction: target });
  } catch (e) {
    // Self-improvement: analyze failure, generate alternatives
    const newStrategy = await stagehand.act({
      action: `The previous selector failed. Analyze the page and find alternative ways to extract: ${target}`
    });

    // Save learning for future use
    await saveSelectorEvolution(url, target, newStrategy);
    return retry(newStrategy);
  }
}
```

**Why It Wins:**
- Solves REAL developer pain (everyone hates broken scrapers)
- Clear before/after demonstration
- Stagehand writes code, Browserbase runs it - perfect sponsor showcase
- The "self-healing" narrative is compelling

**24-Hour Build Plan:**
1. Set up Browserbase + Stagehand integration
2. Pick 3-5 popular sites that change frequently (news, e-commerce)
3. Build selector evolution history storage
4. Implement failure detection and recovery
5. Create dashboard showing recovery events

---

### 3. "AgentColony" - Multi-Agent Ecosystem with Emergent Specialization

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Google Cloud ADK + A2A protocol, Weave for tracking |
| **Self-Improvement** | Agents specialize over time based on task success |
| **Demo Power** | Watch agents naturally develop "expertise areas" |
| **Target Judges** | Aleksa (research), Shadi (infrastructure), Lucas (optimization) |

**Concept:**
A colony of agents that communicate via Google's A2A protocol, where agents specialize over time based on which tasks they succeed at—emergent division of labor through self-improvement.

**Self-Improvement Mechanism:**
```python
from google.adk import Agent, A2AProtocol

class EvolvingAgent(Agent):
    def __init__(self):
        self.competency_scores = defaultdict(lambda: 0.5)

    async def handle_task(self, task: A2AMessage):
        result = await self.attempt(task)

        # Self-improvement: update competency
        if result.success:
            self.competency_scores[task.type] *= 1.1
        else:
            self.competency_scores[task.type] *= 0.9

        # Broadcast updated capabilities to colony
        await self.broadcast_capabilities(self.competency_scores)
```

**Why It Wins:**
- A2A protocol used for its intended purpose: agent coordination
- Emergent behavior is fascinating and demo-able
- Shows deep understanding of Google's agent ecosystem vision
- Research-grade concept with practical implementation

**24-Hour Build Plan:**
1. Set up Google Cloud ADK with A2A
2. Create 3-5 generalist agents
3. Define 3-4 task types with clear success metrics
4. Build task router that learns from competency broadcasts
5. Create visualization dashboard showing specialization emerge

---

### 4. "TrustLoop" - Agent with Earned Autonomy

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Redis (fast permission lookups), Weave (audit trails) |
| **Self-Improvement** | Earns autonomy as it proves reliability |
| **Demo Power** | "Watch the agent graduate from supervised to autonomous" |
| **Target Judges** | Dex (safety), Allie (security), Karan (tool integration) |

**Concept:**
An AI agent that starts with heavy human oversight and earns autonomy as it proves reliability. Self-improves by learning from human corrections.

**Trust Model:**
```
New agent: 100% human oversight
After 100 successful actions in domain X: 50% oversight
After 1000 successful actions: 10% oversight with sampling
One failure: reset trust in that domain
```

**Self-Improvement Mechanism:**
```python
class TrustLoopAgent:
    def __init__(self):
        self.trust_scores = {}  # domain -> trust level
        self.redis = Redis()

    async def request_action(self, action, domain):
        trust = self.trust_scores.get(domain, 0.0)

        if trust < 0.5:
            # Requires human approval
            approved = await self.request_human_approval(action)
            if approved:
                result = await self.execute(action)
                self.update_trust(domain, result.success)
        elif trust < 0.9:
            # Sampling - 50% require approval
            if random.random() < (1 - trust):
                await self.request_human_approval(action)
            result = await self.execute(action)
            self.update_trust(domain, result.success)
        else:
            # Autonomous with logging
            result = await self.execute(action)
            weave.log({"action": action, "result": result, "autonomous": True})
```

**Why It Wins:**
- Directly addresses Dex Horthy's thesis (HumanLayer founder)
- Novel trust model that no one else will build
- Shows production mindset over "cool demo" mindset
- Redis for fast lookups proves infrastructure thinking

**24-Hour Build Plan:**
1. Set up Redis for permission/trust storage
2. Implement graduated trust model
3. Build human approval interface
4. Create Weave integration for audit trails
5. Demo workflow showing trust being earned

---

### 5. "ERA-Lite" - Meta-Agent That Builds Better Agents

**Win Probability: HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Weave (track agent variants), Vercel (deploy best agents) |
| **Self-Improvement** | Generates, tests, and refines specialized agents |
| **Demo Power** | "Our agent's first task was to improve itself" |
| **Target Judges** | Aleksa (research), Matthew (demo), Lucas (optimization) |

**Concept:**
An agent factory that generates, tests, and refines specialized agents. Uses Weave to track which agent architectures perform best.

**Self-Improvement Mechanism:**
```python
class MetaAgent:
    async def evolve_agent(self, task_type: str):
        # Generate agent variants
        variants = []
        for i in range(10):
            config = self.mutate_config(self.best_config[task_type])
            agent = self.create_agent(config)
            variants.append(agent)

        # Test all variants
        results = await asyncio.gather(*[
            self.evaluate_agent(agent, task_type)
            for agent in variants
        ])

        # Track in Weave
        for agent, result in zip(variants, results):
            weave.log({
                "agent_config": agent.config,
                "task_type": task_type,
                "score": result.score
            })

        # Keep best
        best = max(zip(variants, results), key=lambda x: x[1].score)
        self.best_config[task_type] = best[0].config
        return best[0]
```

**Why It Wins:**
- Direct callback to ERA (previous winner)
- "AI that builds AI" is the paradigm shift narrative
- Weave dashboard shows evolution over time
- Technically impressive but achievable

**24-Hour Build Plan:**
1. Define agent configuration space (prompts, tools, parameters)
2. Build mutation/crossover functions
3. Create evaluation harness with test tasks
4. Integrate Weave for tracking
5. Build dashboard showing agent evolution

---

### 6. "MemoryForge" - Agent with Self-Healing Knowledge Graph

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Redis (vector search for memory), Weave (track contradictions) |
| **Self-Improvement** | Finds and resolves contradictions in its own memory |
| **Demo Power** | "Watch the agent discover it was wrong and fix itself" |
| **Target Judges** | Sicheng (Chroma/RAG), Aleksa (research), Lucas (optimization) |

**Concept:**
A personal research assistant that builds and REFINES its knowledge graph over time, using Redis vector search to find contradictions in its own memory and resolve them.

**Self-Improvement Mechanism:**
```python
class MemoryForge:
    async def add_memory(self, content: str):
        embedding = await self.embed(content)

        # Search for conflicting memories
        conflicts = await self.redis.ft("idx:memories").search(
            Query(f"@embedding:[VECTOR_RANGE 0.15 $vec]")
            .return_fields("content", "confidence")
        )

        # Resolve conflicts
        for conflict in conflicts:
            if self.is_contradiction(content, conflict.content):
                resolution = await self.resolve_contradiction(
                    new=content,
                    old=conflict.content
                )
                await self.update_memory(conflict.id, resolution)
                weave.log({
                    "event": "contradiction_resolved",
                    "old": conflict.content,
                    "new": content,
                    "resolution": resolution
                })

        # Store new memory
        await self.redis.hset(f"memory:{id}", mapping={
            "embedding": embedding.tobytes(),
            "content": content,
            "confidence": 0.7,
            "last_validated": timestamp
        })
```

**Why It Wins:**
- Redis isn't just a cache—it's the SUBSTRATE for self-improvement
- Vector search enables "memory introspection"
- Shows sophisticated use of sponsor tech
- Sicheng (Chroma) will appreciate the approach

**24-Hour Build Plan:**
1. Set up Redis with vector search index
2. Pre-load with a specific domain (e.g., AI research papers)
3. Build contradiction detection logic
4. Implement resolution strategies
5. Create visualization of memory health improving

---

### 7. "DeployBot" - Self-Optimizing Vercel Application

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Vercel (deployment + analytics), Weave (track experiments) |
| **Self-Improvement** | A/B tests its own prompts, auto-deploys winners |
| **Demo Power** | "Conversion improved 23% after 3 auto-deployments" |
| **Target Judges** | Jake (Vercel), Matthew (demo), Vjeux (DX) |

**Concept:**
A Vercel-deployed AI app that monitors its own performance metrics and automatically deploys improvements to itself—prompt refinements, caching strategies, and edge function optimizations.

**Self-Improvement Mechanism:**
```typescript
// Edge function with self-improvement hooks
export const config = { runtime: 'edge' };

export default async function handler(req: Request) {
  const variant = await getActivePromptVariant(); // A/B test
  const start = Date.now();

  const response = await generateAIResponse(variant);

  // Log for self-improvement analysis
  await logToAnalytics({
    variant: variant.id,
    latency: Date.now() - start,
    tokenCount: response.usage.total_tokens,
    userSatisfaction: await getUserFeedback()
  });

  // Check if we have statistical significance
  const analysis = await analyzeVariants();
  if (analysis.hasWinner) {
    await deployWinningVariant(analysis.winner);
  }

  return new Response(response.content);
}
```

**Why It Wins:**
- Meta-demonstration: the product improves itself
- Jake Phelps (Vercel) will love seeing Vercel capabilities showcased
- Real metrics proving improvement
- Shows understanding of deployment/analytics integration

**24-Hour Build Plan:**
1. Set up Vercel AI SDK project
2. Implement A/B testing for prompts
3. Create analytics tracking with Weave
4. Build auto-deployment via Vercel API
5. Create dashboard showing improvement over time

---

### 8. "GuardianAgent" - Self-Improving Security Layer

**Win Probability: MEDIUM-HIGH** ⭐⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Weave (audit trails), Redis (fast policy lookups) |
| **Self-Improvement** | Learns new attack patterns, builds defenses automatically |
| **Demo Power** | Show unsafe agent causing chaos → GuardianAgent prevents disaster |
| **Target Judges** | Dex (safety), Allie (security), Karan (tool integration) |

**Concept:**
A security layer that monitors agent actions for safety violations, learns new attack patterns, and builds defenses. Human-in-the-loop for high-risk actions.

**Self-Improvement Mechanism:**
```python
class GuardianAgent:
    def __init__(self):
        self.policy_embeddings = []  # Known bad patterns
        self.redis = Redis()

    async def evaluate_action(self, action: AgentAction) -> Decision:
        # Check against known patterns
        embedding = await self.embed(action.description)
        similar_violations = await self.redis.ft("violations").search(
            Query(f"@embedding:[VECTOR_RANGE 0.2 $vec]")
        )

        if similar_violations:
            # Block and log
            weave.log({
                "event": "action_blocked",
                "action": action,
                "similar_to": similar_violations[0]
            })
            return Decision.BLOCK

        # Risk assessment
        risk = await self.assess_risk(action)
        if risk > 0.7:
            # Human approval required
            approved = await self.request_approval(action, risk)
            if not approved:
                # Learn from rejection
                await self.add_violation_pattern(action)
            return Decision.APPROVED if approved else Decision.BLOCK

        return Decision.ALLOW
```

**Why It Wins:**
- Combines Weave + Redis meaningfully
- Addresses real concerns (Dex, Allie care deeply)
- "Horror story → save" demo is memorable
- Shows production mindset

**24-Hour Build Plan:**
1. Set up Redis for policy/violation storage
2. Build risk assessment model
3. Create human approval interface
4. Implement learning from rejections
5. Prepare demo scenarios showing protection

---

### 9. "NotebookEvolver" - Self-Documenting Research Agent

**Win Probability: MEDIUM** ⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Marimo (reactive notebooks), Weave (track experiments) |
| **Self-Improvement** | Learns which research approaches work vs. fail |
| **Demo Power** | The notebook IS the agent's evolving brain |
| **Target Judges** | Aleksa (research), Sicheng (data), Lucas (ML) |

**Concept:**
An AI research assistant that lives IN a Marimo notebook, runs experiments, and automatically improves its own methodology based on which experiments yield insights vs. dead ends.

**Self-Improvement Mechanism:**
```python
import marimo as mo

@mo.cell
def experiment_runner():
    # Agent proposes experiments
    experiment = agent.propose_experiment(
        goal=research_question,
        past_failures=get_failed_approaches(),
        successful_patterns=get_working_methods()
    )

    # Run and evaluate
    result = run_experiment(experiment)

    # Self-improvement: classify outcome
    if result.insight_score > threshold:
        save_successful_pattern(experiment.methodology)
        mo.md(f"## Success! New pattern learned: {experiment.methodology}")
    else:
        save_failure_reason(experiment, result.why_failed)
        mo.md(f"## Failed: {result.why_failed}. Avoiding this approach.")

    return result
```

**Why It Wins:**
- Marimo's reactivity makes the improvement loop VISIBLE
- The notebook IS the agent's evolving brain
- Reproducibility means judges can verify claims
- Novel use case for notebooks

**24-Hour Build Plan:**
1. Set up Marimo notebook environment
2. Focus on specific research domain (e.g., hyperparameter optimization)
3. Build experiment proposal and evaluation
4. Create methodology memory system
5. Pre-seed with some failures to show evolution

---

### 10. "Daydreamer-Lite" - Video-to-Action Learning Agent

**Win Probability: MEDIUM (High ceiling, high risk)** ⭐⭐⭐

| Aspect | Details |
|--------|---------|
| **Sponsor Tools** | Browserbase (execute learned actions), Weave (track learning) |
| **Self-Improvement** | Watches tutorials, extracts actions, tries them, learns |
| **Demo Power** | Agent watches YouTube tutorial → executes workflow → improves |
| **Target Judges** | Aleksa (research), Shadi (ambitious), Matthew (wow factor) |

**Concept:**
Inspired by the Daydreamer winner. An agent that watches video tutorials, extracts actions, tries them in a browser, and learns from success/failure.

**Self-Improvement Mechanism:**
```python
class DaydreamerLite:
    async def learn_from_video(self, video_url: str):
        # Extract action sequence from video
        frames = await self.extract_frames(video_url)
        actions = await self.vision_model.extract_actions(frames)

        # Attempt in browser
        browser = await Browserbase.create_session()
        results = []

        for action in actions:
            try:
                result = await browser.execute(action)
                results.append({"action": action, "success": True})
            except Exception as e:
                results.append({"action": action, "success": False, "error": str(e)})

                # Learn from failure
                correction = await self.analyze_failure(action, e)
                self.action_corrections[action.type].append(correction)

        # Log learning
        weave.log({
            "video": video_url,
            "actions_extracted": len(actions),
            "success_rate": sum(r["success"] for r in results) / len(results),
            "corrections_learned": len(self.action_corrections)
        })
```

**Why It Wins:**
- Direct callback to the grand prize winner (Daydreamer)
- "GPT moment" narrative framing
- Technically ambitious = high judge respect if it works
- Combines vision + action + learning

**Risk:** Video processing is slow; demo must be bulletproof

**24-Hour Build Plan:**
1. Pre-process 5 tutorial videos for common workflows
2. Set up Browserbase for action execution
3. Build action extraction from video (can use GPT-4V)
4. Implement failure analysis and correction
5. Demo the 6th video being learned LIVE

---

## Judge-Optimized Strategy Matrix

| Project | Dex (Safety) | Kwindla (Voice) | Vjeux (DX/UI) | Matthew (Demo) | Aleksa (Research) | Sicheng (RAG) | Jake (Vercel) |
|---------|:------------:|:---------------:|:-------------:|:--------------:|:-----------------:|:-------------:|:-------------:|
| VoiceCoach | ⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ | ⭐⭐ |
| WebSensei | ⭐ | ⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐ | ⭐⭐ |
| AgentColony | ⭐ | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ |
| TrustLoop | ⭐⭐⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐ | ⭐ |
| ERA-Lite | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐⭐ |
| MemoryForge | ⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ |
| DeployBot | ⭐ | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ | ⭐⭐⭐ |
| GuardianAgent | ⭐⭐⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐ | ⭐ | ⭐ |
| NotebookEvolver | ⭐ | ⭐ | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐ |
| Daydreamer-Lite | ⭐ | ⭐ | ⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐ | ⭐ |

---

## Demo Strategy

### The 5-Minute Demo Structure

```
1. HOOK (15 seconds)
   "What if [bold claim]?"
   Example: "What if your scrapers could fix themselves?"

2. PROBLEM (30 seconds)
   Show the pain point visually
   Example: Show a broken scraper, frustrated developer

3. SOLUTION (2 minutes)
   Live demo of self-improvement happening
   Example: Break a scraper live, watch it recover

4. METRICS (30 seconds)
   Before/after numbers from Weave
   Example: "95% recovery rate, 3x faster than manual fixes"

5. VISION (15 seconds)
   "This is how [domain] will work in 2 years"
   Example: "This is how web automation will work - resilient by default"
```

### Demo Tips

- **Pre-load data**: Have improvement history ready to show
- **Have a backup**: If live demo fails, have a recorded version
- **Make metrics visible**: Weave dashboards should be open and ready
- **Practice the narrative**: The story matters as much as the tech
- **End with the tagline**: Leave judges with a memorable phrase

---

## Final Recommendations

### If You Want to WIN (Safest Path)

**Build VoiceCoach or WebSensei**
- High demo impact
- Clear sponsor alignment (Daily or Browserbase)
- Appeals to 4+ judges
- Technically impressive but achievable in 24 hours

### If You Want to Make a Statement (Higher Risk, Higher Reward)

**Build AgentColony or ERA-Lite**
- Research-grade ambition
- "Paradigm shift" narrative
- Aleksa + Shadi will love it
- Needs flawless demo preparation

### If You Care About Safety/Production

**Build TrustLoop or GuardianAgent**
- Dex + Allie are strong advocates
- Differentiates from "cool demo" projects
- Shows production mindset

### Multi-Sponsor Prize Strategy

To win BOTH a main prize AND a sponsor prize:

| Main Prize Target | Sponsor Prize | Recommended Project |
|-------------------|---------------|---------------------|
| Grand Prize | Best Use of Daily | VoiceCoach |
| Grand Prize | Best Use of Browserbase | WebSensei |
| Best Self-Improving | Best Use of Weave | ERA-Lite or MemoryForge |
| Runner-up | Best Use of Vercel | DeployBot |
| Runner-up | Best Use of Google Cloud | AgentColony |

---

## Quick Reference: Project Comparison

| Project | Difficulty | Demo Impact | Judge Appeal | Sponsor Fit |
|---------|:----------:|:-----------:|:------------:|:-----------:|
| VoiceCoach | Medium | Very High | Very High | Daily ⭐⭐⭐ |
| WebSensei | Medium | Very High | High | Browserbase ⭐⭐⭐ |
| AgentColony | High | High | High | Google ⭐⭐⭐ |
| TrustLoop | Medium | Medium | High | Redis/Weave ⭐⭐ |
| ERA-Lite | High | High | High | Weave ⭐⭐⭐ |
| MemoryForge | Medium | Medium | Medium | Redis ⭐⭐⭐ |
| DeployBot | Medium | High | Medium | Vercel ⭐⭐⭐ |
| GuardianAgent | Medium | Medium | High | Weave/Redis ⭐⭐ |
| NotebookEvolver | Medium | Medium | Medium | Marimo ⭐⭐⭐ |
| Daydreamer-Lite | Very High | Very High | High | Browserbase ⭐⭐ |

---

## Appendix: Sponsor Prize Criteria

### Best Use of Weave ($1,000 + TRMNL)
- Deep integration with tracing
- Meaningful use of observability for self-improvement
- Dashboard showing agent evolution

### Best Use of Daily/Pipecat
- Real-time voice/audio quality
- Low latency (<500ms)
- Creative use of Pipecat pipeline

### Best Use of Redis
- Vector search for memory/retrieval
- Fast state management
- Meaningful caching strategy

### Best Use of Browserbase
- Reliable web automation
- Creative use of Stagehand
- Self-healing patterns

### Best Use of Vercel
- Edge deployment
- AI SDK integration
- Performance optimization

### Best Use of Google Cloud
- ADK/A2A protocol usage
- Infrastructure sophistication
- Agent-to-agent communication

---

*Good luck at WeaveHacks! Remember: the winning project combines technical depth with polished UX while addressing safety concerns. Make judges say: "That's impressive, I could actually use that, and I'd trust it in production."*
